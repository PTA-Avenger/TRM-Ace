{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true,"mount_file_id":"1J6M-N9ELbHqDd1evU5Tv9QbI1D3VIakO","authorship_tag":"ABX9TyNxmfy9W77Wga4eihheYlcy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f9b6732311724094a0abfb5f496cca3b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7bdd7578393f4592a70af9f6d2bc799b","IPY_MODEL_d06a1a5cad2541e3a16de87e5408de95","IPY_MODEL_d152779bc4b146ea9d0b76c71c473c47"],"layout":"IPY_MODEL_a32edc606726478eac09e00404a7751b"}},"7bdd7578393f4592a70af9f6d2bc799b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b67bb4f5055b4f3b92c71444a9812027","placeholder":"​","style":"IPY_MODEL_a229afe3af944a128446ba4a579d46db","value":"model.safetensors: 100%"}},"d06a1a5cad2541e3a16de87e5408de95":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_21ed05584c7747abb04a99416068499f","max":5702746403,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3f3a6f3b982649f0a8a95e8a0d79538c","value":5702746403}},"d152779bc4b146ea9d0b76c71c473c47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d13f0d3917f4fa5b8badb9ecfb71fd2","placeholder":"​","style":"IPY_MODEL_f109dc14f0c1426eab419914d40446f6","value":" 5.70G/5.70G [00:47&lt;00:00, 268MB/s]"}},"a32edc606726478eac09e00404a7751b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b67bb4f5055b4f3b92c71444a9812027":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a229afe3af944a128446ba4a579d46db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21ed05584c7747abb04a99416068499f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f3a6f3b982649f0a8a95e8a0d79538c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0d13f0d3917f4fa5b8badb9ecfb71fd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f109dc14f0c1426eab419914d40446f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58114d2cc4194eb9bd2ed47e68849c39":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8421d79642834b1784bd3546a27c70b3","IPY_MODEL_538957d6939a4bdf84832b3cfcae30da","IPY_MODEL_3c5da1036f804275b894d1ce0d0d5a9b"],"layout":"IPY_MODEL_9b247cd113034018a1c1a7280aa2d3e7"}},"8421d79642834b1784bd3546a27c70b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57bed12cb2d9450091df96c6bf176421","placeholder":"​","style":"IPY_MODEL_d704ebd522cb4ce6ae37b414ecac6851","value":"generation_config.json: 100%"}},"538957d6939a4bdf84832b3cfcae30da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_462c0573cffc4163bd8e8788f3a3c97b","max":220,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d423fada2104981b7c662933eefdd11","value":220}},"3c5da1036f804275b894d1ce0d0d5a9b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e80bf9dcad744828773262bc0b136e3","placeholder":"​","style":"IPY_MODEL_929cc64dab9644a7afb32b293602a1b1","value":" 220/220 [00:00&lt;00:00, 22.4kB/s]"}},"9b247cd113034018a1c1a7280aa2d3e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57bed12cb2d9450091df96c6bf176421":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d704ebd522cb4ce6ae37b414ecac6851":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"462c0573cffc4163bd8e8788f3a3c97b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d423fada2104981b7c662933eefdd11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e80bf9dcad744828773262bc0b136e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"929cc64dab9644a7afb32b293602a1b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2720f159c2934df1bf07fad530c42f48":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f5429ff4f6c4077b44666c4e3906da8","IPY_MODEL_e763c6a85fe049a8a806fb48d5f84f83","IPY_MODEL_21429802ab2e4eec8f8c44135d8687a9"],"layout":"IPY_MODEL_4b9779fb0b7643568f85f15a03dcfb43"}},"4f5429ff4f6c4077b44666c4e3906da8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_236874874ac045a5af2f3aa3c1a60355","placeholder":"​","style":"IPY_MODEL_631764a4485b4a10999fae7875764476","value":"tokenizer_config.json: "}},"e763c6a85fe049a8a806fb48d5f84f83":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97e3e89f0e334e2190e0e47102068b06","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1bd942cb27b049a298f3d5c93467eee4","value":1}},"21429802ab2e4eec8f8c44135d8687a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77b5a63fa45c4d708ea5ff8a54e4d26a","placeholder":"​","style":"IPY_MODEL_6b020b73081e40d6a7d4664d874d9fec","value":" 51.1k/? [00:00&lt;00:00, 5.17MB/s]"}},"4b9779fb0b7643568f85f15a03dcfb43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"236874874ac045a5af2f3aa3c1a60355":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"631764a4485b4a10999fae7875764476":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97e3e89f0e334e2190e0e47102068b06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"1bd942cb27b049a298f3d5c93467eee4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"77b5a63fa45c4d708ea5ff8a54e4d26a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b020b73081e40d6a7d4664d874d9fec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de36785569684e88962d18517de779d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5f7de7153ed4fed9bb2866226ac76f9","IPY_MODEL_d990446c2436475ebcac66bf6c0999d8","IPY_MODEL_160ec2bc412942398b827b1c107cec66"],"layout":"IPY_MODEL_b99b2029a2b14a32acfe0041e6ca9871"}},"b5f7de7153ed4fed9bb2866226ac76f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a30f199069db42149a18306893c212f1","placeholder":"​","style":"IPY_MODEL_52bc346fa9e444a1a6f5ed2e3485a378","value":"tokenizer.json: "}},"d990446c2436475ebcac66bf6c0999d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5266839c0d054d1cbf5f19654c5b7ef3","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c630ac31110040129410f8083e513d82","value":1}},"160ec2bc412942398b827b1c107cec66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88885dce8dfb4e90a9096ade2608f057","placeholder":"​","style":"IPY_MODEL_441c08b8908349d7a7e1988f7600dcb3","value":" 9.09M/? [00:00&lt;00:00, 107MB/s]"}},"b99b2029a2b14a32acfe0041e6ca9871":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a30f199069db42149a18306893c212f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52bc346fa9e444a1a6f5ed2e3485a378":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5266839c0d054d1cbf5f19654c5b7ef3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c630ac31110040129410f8083e513d82":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88885dce8dfb4e90a9096ade2608f057":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"441c08b8908349d7a7e1988f7600dcb3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ab9c1cf6d584dd9becf4ec151219ce6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_56613b724d9043f5821f3d5fb1baeb2d","IPY_MODEL_bc9f51d091044adf8501ee16e83d1571","IPY_MODEL_7bb6db91b5084738918917a5c208886f"],"layout":"IPY_MODEL_125bf10901ea499392f8411235d57145"}},"56613b724d9043f5821f3d5fb1baeb2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccf4415b90004a499b58c2e4e011ce25","placeholder":"​","style":"IPY_MODEL_9c7f205d9c7548daa9ef0d885cbd8233","value":"special_tokens_map.json: 100%"}},"bc9f51d091044adf8501ee16e83d1571":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a43feaa4eb1416eb4c3532fbe2cc338","max":345,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c217f0453e14dfcb7426f123f62b108","value":345}},"7bb6db91b5084738918917a5c208886f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e866c942aca48c688ff10b2f04190a0","placeholder":"​","style":"IPY_MODEL_41880f75c92f4d7c839f46c49774a588","value":" 345/345 [00:00&lt;00:00, 34.8kB/s]"}},"125bf10901ea499392f8411235d57145":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccf4415b90004a499b58c2e4e011ce25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c7f205d9c7548daa9ef0d885cbd8233":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a43feaa4eb1416eb4c3532fbe2cc338":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c217f0453e14dfcb7426f123f62b108":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e866c942aca48c688ff10b2f04190a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41880f75c92f4d7c839f46c49774a588":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1cfa60975118408f9197a79c264733b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30a47f772f174a6f82d58d49e78b3bbc","IPY_MODEL_9cf560ed634445abb49981b380d5e82a","IPY_MODEL_f78f4442c00345ff851b1f7ebae6c0b6"],"layout":"IPY_MODEL_90aa486e21a04258953f8e07a5cb179b"}},"30a47f772f174a6f82d58d49e78b3bbc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0306fb13128f45b78e04e476d4cfdac0","placeholder":"​","style":"IPY_MODEL_240e4415dc0844438445e5082b500a0a","value":"Generating train split: "}},"9cf560ed634445abb49981b380d5e82a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18ebec704ea84e8f8c76d1cd97be6f7c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9636e0458c664bf78073d4921121e7c0","value":1}},"f78f4442c00345ff851b1f7ebae6c0b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bad0c270740457c95af31050c59aab9","placeholder":"​","style":"IPY_MODEL_20617a73e0b64d499ee199ef4c4bface","value":" 18/0 [00:00&lt;00:00, 219.80 examples/s]"}},"90aa486e21a04258953f8e07a5cb179b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0306fb13128f45b78e04e476d4cfdac0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"240e4415dc0844438445e5082b500a0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18ebec704ea84e8f8c76d1cd97be6f7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"9636e0458c664bf78073d4921121e7c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4bad0c270740457c95af31050c59aab9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20617a73e0b64d499ee199ef4c4bface":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42548271952d48518797a6d3221bb8d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb4427af6f4b43bb8a3ce46e48a23327","IPY_MODEL_cc53c6bc864a4e0cbdb2e43adf423c7e","IPY_MODEL_180e69a355374590be55a096f73d5862"],"layout":"IPY_MODEL_84422c966b0c40fb877f749f08d30aa8"}},"eb4427af6f4b43bb8a3ce46e48a23327":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_719a76abffa44219b8b64c6bb35d1d7b","placeholder":"​","style":"IPY_MODEL_667a40450970464a928c50201146c25d","value":"Map: 100%"}},"cc53c6bc864a4e0cbdb2e43adf423c7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17bf4ae4e23e4e459069eb382fd61bef","max":18,"min":0,"orientation":"horizontal","style":"IPY_MODEL_41cfaed68cb64b049420586bd6a32447","value":18}},"180e69a355374590be55a096f73d5862":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04089c22e8e6418ba5408f2b765264a2","placeholder":"​","style":"IPY_MODEL_6c1e9564b09446398c5c5ac09f9f88b6","value":" 18/18 [00:00&lt;00:00, 552.67 examples/s]"}},"84422c966b0c40fb877f749f08d30aa8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"719a76abffa44219b8b64c6bb35d1d7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"667a40450970464a928c50201146c25d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17bf4ae4e23e4e459069eb382fd61bef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41cfaed68cb64b049420586bd6a32447":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04089c22e8e6418ba5408f2b765264a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c1e9564b09446398c5c5ac09f9f88b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c48884b623a4e0eaabcc1acac86f536":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad5ee234866348e99ea401e54f9752eb","IPY_MODEL_4690e331416b4b0585ca5b73aa05af9b","IPY_MODEL_9683df60c8e74c0599ace577fae39a6d"],"layout":"IPY_MODEL_9af5b6bd05f14e8ea800bc864c8588af"}},"ad5ee234866348e99ea401e54f9752eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_794c782794f043f797abd285eff06996","placeholder":"​","style":"IPY_MODEL_fa285b1067c34adfbf3676cf185a4c65","value":"Unsloth: Tokenizing [&quot;text&quot;] (num_proc=6): 100%"}},"4690e331416b4b0585ca5b73aa05af9b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_108d868ab1c94dee9cd14c18ffa2fbb7","max":18,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2f36425707c4c3793a77d415852d813","value":18}},"9683df60c8e74c0599ace577fae39a6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbfbecc09a3c4a8584ddb7db9d0e42d7","placeholder":"​","style":"IPY_MODEL_199ee141a67145358b7e3422ab68c0e5","value":" 18/18 [00:05&lt;00:00,  6.13 examples/s]"}},"9af5b6bd05f14e8ea800bc864c8588af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"794c782794f043f797abd285eff06996":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa285b1067c34adfbf3676cf185a4c65":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"108d868ab1c94dee9cd14c18ffa2fbb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2f36425707c4c3793a77d415852d813":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bbfbecc09a3c4a8584ddb7db9d0e42d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"199ee141a67145358b7e3422ab68c0e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63013347e9394dbd9903f50bd4147ab1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f66c6dd9bc4f4480b18855ae4b1c4c5b","IPY_MODEL_c650733f2b574106a6e4f1f033d022bf","IPY_MODEL_82038b94d3094250aa7821753e4d79ed"],"layout":"IPY_MODEL_a4e000a219014e38ac0d46f5932384cd"}},"f66c6dd9bc4f4480b18855ae4b1c4c5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_041aeb9d908b4a41a12907cac902e080","placeholder":"​","style":"IPY_MODEL_bbe4664ab5e547aebd5cdb6635265a92","value":"model.safetensors: 100%"}},"c650733f2b574106a6e4f1f033d022bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3a36f320490491aa8761b556e5a13d9","max":5702746403,"min":0,"orientation":"horizontal","style":"IPY_MODEL_10de844a69c647a7b485af82e709c752","value":5702746403}},"82038b94d3094250aa7821753e4d79ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2aa0cd4afd940b28539a8d256d31140","placeholder":"​","style":"IPY_MODEL_d6d895cc71f94c80970c0537b7993257","value":" 5.70G/5.70G [00:47&lt;00:00, 215MB/s]"}},"a4e000a219014e38ac0d46f5932384cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"041aeb9d908b4a41a12907cac902e080":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbe4664ab5e547aebd5cdb6635265a92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3a36f320490491aa8761b556e5a13d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10de844a69c647a7b485af82e709c752":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f2aa0cd4afd940b28539a8d256d31140":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6d895cc71f94c80970c0537b7993257":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1dd42df13838475c8db23b40029995f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2088691f6da947d1b92bdc7f2c5f752c","IPY_MODEL_7ebe37ec5c7447b1a630247128ad14ad","IPY_MODEL_17789a1a6162446e89772ba4c8abafff"],"layout":"IPY_MODEL_5fad45c63bd6426e96b8308936c525d0"}},"2088691f6da947d1b92bdc7f2c5f752c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e2320425b4c4af0b13b68368561479d","placeholder":"​","style":"IPY_MODEL_de478695399c42dbb12723c800e47fa1","value":"generation_config.json: 100%"}},"7ebe37ec5c7447b1a630247128ad14ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_756afc08c975470f802d751dd8eba2b8","max":220,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5dc08bc0c9d5419ea666b8e34df3b72b","value":220}},"17789a1a6162446e89772ba4c8abafff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb47746d83d04cce953089e7bf6a26ca","placeholder":"​","style":"IPY_MODEL_7d578038959a4f5ba71dba3b372dac3a","value":" 220/220 [00:00&lt;00:00, 24.6kB/s]"}},"5fad45c63bd6426e96b8308936c525d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e2320425b4c4af0b13b68368561479d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de478695399c42dbb12723c800e47fa1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"756afc08c975470f802d751dd8eba2b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dc08bc0c9d5419ea666b8e34df3b72b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb47746d83d04cce953089e7bf6a26ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d578038959a4f5ba71dba3b372dac3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce0328d6a29441058fc3a64a418d5b81":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_62e202749c3c4b8ebac1e007b03f4795","IPY_MODEL_a76c3560cc0a4ed48749851b13524a88","IPY_MODEL_24f3a8f092cc48f5b5baa5c8ffdbbc2f"],"layout":"IPY_MODEL_51984d0e203445c59d5a2cf000a072bc"}},"62e202749c3c4b8ebac1e007b03f4795":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_714412b1eeef4309a1678447d6090513","placeholder":"​","style":"IPY_MODEL_46ef56c1cdf844748658ec875d1d84f0","value":"tokenizer_config.json: "}},"a76c3560cc0a4ed48749851b13524a88":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7d4f213d59a4b09a56c15c2a0036dee","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_683f7765d8234b558e2154c75ce2a8c2","value":1}},"24f3a8f092cc48f5b5baa5c8ffdbbc2f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d29187628eb544c4940d52e2d49a1167","placeholder":"​","style":"IPY_MODEL_9c6c3678aaf148efad71ae9fbb8a98f9","value":" 51.1k/? [00:00&lt;00:00, 3.44MB/s]"}},"51984d0e203445c59d5a2cf000a072bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"714412b1eeef4309a1678447d6090513":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46ef56c1cdf844748658ec875d1d84f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7d4f213d59a4b09a56c15c2a0036dee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"683f7765d8234b558e2154c75ce2a8c2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d29187628eb544c4940d52e2d49a1167":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c6c3678aaf148efad71ae9fbb8a98f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49d3c32377b64d55968f363af2a0b7ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2108caec88404408a752fe3237b8dcaf","IPY_MODEL_692a1a92436845d38a600ad1999c2d2f","IPY_MODEL_fcebe729f7b04c79bfa02a31ab6ec9ac"],"layout":"IPY_MODEL_065fb887e01b46cbb63578d547cab083"}},"2108caec88404408a752fe3237b8dcaf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c68ca8c4ae141819def6eb7afea8222","placeholder":"​","style":"IPY_MODEL_8823364b09eb4576a7d3c1f76407da53","value":"tokenizer.json: "}},"692a1a92436845d38a600ad1999c2d2f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f98fd74a9fea4c49919e85501c8b3740","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_234054cf1ea840cd9407eb13205d114a","value":1}},"fcebe729f7b04c79bfa02a31ab6ec9ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67e5a0c67a7b44638ea790c8676b88c6","placeholder":"​","style":"IPY_MODEL_9f5a94f73d0c4c0a84628a20e18a1b9a","value":" 9.09M/? [00:00&lt;00:00, 106MB/s]"}},"065fb887e01b46cbb63578d547cab083":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c68ca8c4ae141819def6eb7afea8222":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8823364b09eb4576a7d3c1f76407da53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f98fd74a9fea4c49919e85501c8b3740":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"234054cf1ea840cd9407eb13205d114a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"67e5a0c67a7b44638ea790c8676b88c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f5a94f73d0c4c0a84628a20e18a1b9a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"014daa36490a4b13ae4004b359adb600":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d66d9389f12f47c6ab94360e4ad039a7","IPY_MODEL_cc27b9a8c754483fbc22e973d94de1f6","IPY_MODEL_0f4cb1781a264c748e014ef56d1d5a0f"],"layout":"IPY_MODEL_de40013a39714cc1ad72fbead962542d"}},"d66d9389f12f47c6ab94360e4ad039a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_175fc400c62749728c0c0944f40071d1","placeholder":"​","style":"IPY_MODEL_64e99f4a2d6c47e496b3d82797d909b5","value":"special_tokens_map.json: 100%"}},"cc27b9a8c754483fbc22e973d94de1f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d65faaee929045928d8fbf55c296c3a2","max":345,"min":0,"orientation":"horizontal","style":"IPY_MODEL_94d39236d4854cef92836aedb299dfb3","value":345}},"0f4cb1781a264c748e014ef56d1d5a0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11205aaf9cda42679bb177173d3db310","placeholder":"​","style":"IPY_MODEL_65ebed436db944e5a0fdc253fdbab5f5","value":" 345/345 [00:00&lt;00:00, 41.4kB/s]"}},"de40013a39714cc1ad72fbead962542d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"175fc400c62749728c0c0944f40071d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64e99f4a2d6c47e496b3d82797d909b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d65faaee929045928d8fbf55c296c3a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94d39236d4854cef92836aedb299dfb3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"11205aaf9cda42679bb177173d3db310":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65ebed436db944e5a0fdc253fdbab5f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"753bd1bc8af04a108494cbdb31f36548":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_87a43585c391434f826e6d2afe11f256","IPY_MODEL_0e68aa3acebf43f0bc959ea11cafaa0d","IPY_MODEL_c4cac32ceac04ada9bb3c07e7a191f80"],"layout":"IPY_MODEL_d9eb1d0697ec4ff0b7810e9659220027"}},"87a43585c391434f826e6d2afe11f256":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52d0e9b676ec493d95848ea2c6f6f004","placeholder":"​","style":"IPY_MODEL_a12aa98081ac451dbd2f3a5dacb7d8b5","value":"modules.json: 100%"}},"0e68aa3acebf43f0bc959ea11cafaa0d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_775c8cee12db44bbb5b034c79571547a","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4fbdd81464f143fb9391bbe47c443a07","value":349}},"c4cac32ceac04ada9bb3c07e7a191f80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7f15bf2c8ea4d0a86cf2d40cd63015e","placeholder":"​","style":"IPY_MODEL_fc58ac93a3be4b3d9c0a674a9b20eca3","value":" 349/349 [00:00&lt;00:00, 21.5kB/s]"}},"d9eb1d0697ec4ff0b7810e9659220027":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52d0e9b676ec493d95848ea2c6f6f004":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a12aa98081ac451dbd2f3a5dacb7d8b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"775c8cee12db44bbb5b034c79571547a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fbdd81464f143fb9391bbe47c443a07":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7f15bf2c8ea4d0a86cf2d40cd63015e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc58ac93a3be4b3d9c0a674a9b20eca3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9cd03bde36a457ab316c2cf02a8b1ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78d9a6ffff354d849da7dba02e58dc4c","IPY_MODEL_666d7e3357724ad3a2707bf5db296e0d","IPY_MODEL_339fca2dd41d48a8a97d0d28555a943f"],"layout":"IPY_MODEL_3b9b71c25076466da85d4d4ca107f62e"}},"78d9a6ffff354d849da7dba02e58dc4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de229abcf0fc473a91f7dbb47b7adc55","placeholder":"​","style":"IPY_MODEL_a7f606b5bf8d466c96dc42919724812f","value":"config_sentence_transformers.json: 100%"}},"666d7e3357724ad3a2707bf5db296e0d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb6d366ee69a4919b90061f4c4c2b109","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_10bd1cd0067544548466d55c0ff60cc1","value":116}},"339fca2dd41d48a8a97d0d28555a943f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc8bd780293046bab3f04d91e08d0fa3","placeholder":"​","style":"IPY_MODEL_bf83042f844d432c8ad282e74f949bf8","value":" 116/116 [00:00&lt;00:00, 8.15kB/s]"}},"3b9b71c25076466da85d4d4ca107f62e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de229abcf0fc473a91f7dbb47b7adc55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7f606b5bf8d466c96dc42919724812f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb6d366ee69a4919b90061f4c4c2b109":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10bd1cd0067544548466d55c0ff60cc1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc8bd780293046bab3f04d91e08d0fa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf83042f844d432c8ad282e74f949bf8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4cac8db98914396b5bd373dd1577126":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1ccb9d95102440a881e50bc129911903","IPY_MODEL_963905628de5436f9f784a3778405c34","IPY_MODEL_e25fd77da3f7467f935e171eef4e3a07"],"layout":"IPY_MODEL_2e789e819ef2464b84dd09175ef788bd"}},"1ccb9d95102440a881e50bc129911903":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ffed0ed5e5542d39fae794f4e8c976a","placeholder":"​","style":"IPY_MODEL_e108cc0d9f0c45a39f322796a1f5d204","value":"README.md: "}},"963905628de5436f9f784a3778405c34":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6c0316ea77548b2b4365dd2a680b31c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d0dddf643b7c47c087a24e0628828386","value":1}},"e25fd77da3f7467f935e171eef4e3a07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_613c2ddc46e04dc7ac17cfde82468da6","placeholder":"​","style":"IPY_MODEL_6c73e4c652354a55b0fe2091420cf4e3","value":" 10.5k/? [00:00&lt;00:00, 787kB/s]"}},"2e789e819ef2464b84dd09175ef788bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ffed0ed5e5542d39fae794f4e8c976a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e108cc0d9f0c45a39f322796a1f5d204":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6c0316ea77548b2b4365dd2a680b31c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d0dddf643b7c47c087a24e0628828386":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"613c2ddc46e04dc7ac17cfde82468da6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c73e4c652354a55b0fe2091420cf4e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"549807cf84de4c87a1de5dd24fa4d263":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1343c094073c40d98c9b776f6526f696","IPY_MODEL_cefe33e01d0f48aa88c73feda3386be0","IPY_MODEL_39acfdd2588d471bb081f6186fc5ded0"],"layout":"IPY_MODEL_1de6d7208eaa4923be59c28a85befa0a"}},"1343c094073c40d98c9b776f6526f696":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc42b9335f454490897c219b69ff71ea","placeholder":"​","style":"IPY_MODEL_8d458ea1b15d4709ba179d939017ef46","value":"sentence_bert_config.json: 100%"}},"cefe33e01d0f48aa88c73feda3386be0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbdbedaf45e947988ebe3393477acf7f","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b7a4764d228447094d7264ce0205d63","value":53}},"39acfdd2588d471bb081f6186fc5ded0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f3c9553b26944969b6afaea48ac9478","placeholder":"​","style":"IPY_MODEL_ccebb7f2ee3746a493e4e4035acb2810","value":" 53.0/53.0 [00:00&lt;00:00, 5.04kB/s]"}},"1de6d7208eaa4923be59c28a85befa0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc42b9335f454490897c219b69ff71ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d458ea1b15d4709ba179d939017ef46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bbdbedaf45e947988ebe3393477acf7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b7a4764d228447094d7264ce0205d63":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f3c9553b26944969b6afaea48ac9478":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccebb7f2ee3746a493e4e4035acb2810":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"846d0b7bc410470f9ca9ade999fc8e79":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e2b48e0dc61345c1a56c589b94ca2e50","IPY_MODEL_1ae81baa1ec24ffca8b26aa642581cc0","IPY_MODEL_777a9be290ef4850a6774f05a2cdaaf2"],"layout":"IPY_MODEL_8576ccd49456449091c7cabfa0bdc3f8"}},"e2b48e0dc61345c1a56c589b94ca2e50":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_587a7bfbd5e4474f862fead4a73a22a3","placeholder":"​","style":"IPY_MODEL_fbe30fbb05d24b79a5c147e5345e5b59","value":"config.json: 100%"}},"1ae81baa1ec24ffca8b26aa642581cc0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f579fe2e65e8439ab63e07ceeaf26fd7","max":612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_af2cde50cf054250b57cf6f87b126ef5","value":612}},"777a9be290ef4850a6774f05a2cdaaf2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f58386813231497c9f4c578854c01728","placeholder":"​","style":"IPY_MODEL_f7f5a38a301f4771ab675a9252d72211","value":" 612/612 [00:00&lt;00:00, 52.2kB/s]"}},"8576ccd49456449091c7cabfa0bdc3f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"587a7bfbd5e4474f862fead4a73a22a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbe30fbb05d24b79a5c147e5345e5b59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f579fe2e65e8439ab63e07ceeaf26fd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af2cde50cf054250b57cf6f87b126ef5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f58386813231497c9f4c578854c01728":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7f5a38a301f4771ab675a9252d72211":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ea423ae61b74e8183a3e68b8912bb2f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_650ce65d235846088180696118d46916","IPY_MODEL_ef9b1624862144b1ad364dcfaa68f461","IPY_MODEL_4e3a4bbee78f461b83b6b009b3d60343"],"layout":"IPY_MODEL_8bce3c9c8a7f4f149b9c22de8fcd2e66"}},"650ce65d235846088180696118d46916":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bda12176d8ae4977bc864d139226d61a","placeholder":"​","style":"IPY_MODEL_ab5952c772134d9fa0e782da0fa3422b","value":"model.safetensors: 100%"}},"ef9b1624862144b1ad364dcfaa68f461":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2744a00e28614a51bcb4961ef0b51cd3","max":90868376,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73ac1d0c7fe746e5af9d45ba7f58142e","value":90868376}},"4e3a4bbee78f461b83b6b009b3d60343":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff1c24ae1b12460a85982e18d28d8447","placeholder":"​","style":"IPY_MODEL_41197e18321645bf9679ee9cfcd6f91b","value":" 90.9M/90.9M [00:00&lt;00:00, 155MB/s]"}},"8bce3c9c8a7f4f149b9c22de8fcd2e66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bda12176d8ae4977bc864d139226d61a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab5952c772134d9fa0e782da0fa3422b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2744a00e28614a51bcb4961ef0b51cd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73ac1d0c7fe746e5af9d45ba7f58142e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff1c24ae1b12460a85982e18d28d8447":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41197e18321645bf9679ee9cfcd6f91b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b365a4bcd3ac4e929f560979703e5697":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e076f4369dec4b7295b9b83500a12321","IPY_MODEL_ae9351de3d90429b943227acbc63e14f","IPY_MODEL_0f3942c081d948b58823525e97da9c43"],"layout":"IPY_MODEL_78824bf9f50241bfa11d2f8ea58cd9e3"}},"e076f4369dec4b7295b9b83500a12321":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5f3dc5b89754d57b19221bb8ad8744f","placeholder":"​","style":"IPY_MODEL_cb119af7b7234ddbb3287620ca2e8750","value":"tokenizer_config.json: 100%"}},"ae9351de3d90429b943227acbc63e14f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b998a6181f447dfb83a366685f5622f","max":350,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d26cd009de6a434497aec60358af643d","value":350}},"0f3942c081d948b58823525e97da9c43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76ee14b5c63940028b290ca25ef23307","placeholder":"​","style":"IPY_MODEL_f11791f300334b20a31dee4488822d53","value":" 350/350 [00:00&lt;00:00, 41.3kB/s]"}},"78824bf9f50241bfa11d2f8ea58cd9e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5f3dc5b89754d57b19221bb8ad8744f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb119af7b7234ddbb3287620ca2e8750":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b998a6181f447dfb83a366685f5622f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d26cd009de6a434497aec60358af643d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76ee14b5c63940028b290ca25ef23307":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f11791f300334b20a31dee4488822d53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06712d4273cd4d5b8d5c30a3c20e9f6b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_216d298662604c9ca8bced2cc6d54057","IPY_MODEL_44cb27fe9b594c22a33d90ee2fbbb15b","IPY_MODEL_db9d785bae6f416a940122051cbfd1a1"],"layout":"IPY_MODEL_69322d94903944d3a0b5eecc57c23fa3"}},"216d298662604c9ca8bced2cc6d54057":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4ab7ac3864d4044810426c55463dbaf","placeholder":"​","style":"IPY_MODEL_e62fc72aa2864d3ea17aabf16994fba4","value":"vocab.txt: "}},"44cb27fe9b594c22a33d90ee2fbbb15b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c05236c12c4f4dad888f877d917f663d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5695b14a0dae4e7e91a2fef18907be79","value":1}},"db9d785bae6f416a940122051cbfd1a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d411fa1fbfa847619f91f15827a77bdc","placeholder":"​","style":"IPY_MODEL_20d7003c82164b5cb3a32cd9b03c3762","value":" 232k/? [00:00&lt;00:00, 13.9MB/s]"}},"69322d94903944d3a0b5eecc57c23fa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4ab7ac3864d4044810426c55463dbaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e62fc72aa2864d3ea17aabf16994fba4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c05236c12c4f4dad888f877d917f663d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"5695b14a0dae4e7e91a2fef18907be79":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d411fa1fbfa847619f91f15827a77bdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20d7003c82164b5cb3a32cd9b03c3762":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6b2e9d395d046c9801acaeb1b858b71":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45752886756c490aba116f0dae5751e5","IPY_MODEL_8c7b8779e3184d3e84570590156c2eed","IPY_MODEL_feb7c1172aed485998fea5acfd24a3f6"],"layout":"IPY_MODEL_4edd13f53eb24da78b28de40cf8eb773"}},"45752886756c490aba116f0dae5751e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b96448e122d40a0b61cb0ab23822c44","placeholder":"​","style":"IPY_MODEL_172f09b9a298488aa07e7d1719820aa8","value":"tokenizer.json: "}},"8c7b8779e3184d3e84570590156c2eed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7afc524d18674dd9b70aad5a44261c29","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27fd38671e4f4b9cb8dcb9a6a922c7db","value":1}},"feb7c1172aed485998fea5acfd24a3f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6754c89b0b5f471c8069e092d6c3f2ab","placeholder":"​","style":"IPY_MODEL_a0a5cf21deb549caa545658f527a2b10","value":" 466k/? [00:00&lt;00:00, 20.9MB/s]"}},"4edd13f53eb24da78b28de40cf8eb773":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b96448e122d40a0b61cb0ab23822c44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"172f09b9a298488aa07e7d1719820aa8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7afc524d18674dd9b70aad5a44261c29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"27fd38671e4f4b9cb8dcb9a6a922c7db":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6754c89b0b5f471c8069e092d6c3f2ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0a5cf21deb549caa545658f527a2b10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b73dda579ea9460c814c0f9c40ade36f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bae89b82e9fd4973b88f7823effcbf08","IPY_MODEL_22ac103b27b34b95a7aed0ea801964f6","IPY_MODEL_14dd443500af41788e00d596505e558e"],"layout":"IPY_MODEL_b9a4aca0a2f64fd19db62ba864d0589f"}},"bae89b82e9fd4973b88f7823effcbf08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_010f617398ee4354b48908833ec42048","placeholder":"​","style":"IPY_MODEL_7c5b0e543af243b0b21093dfa3282314","value":"special_tokens_map.json: 100%"}},"22ac103b27b34b95a7aed0ea801964f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0788e8d67a745fcad8ac064f42bbfe4","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81e24a0f3eda4628b2e53ad0f985c43e","value":112}},"14dd443500af41788e00d596505e558e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3eaa53f9e0d54308961a8e8624920571","placeholder":"​","style":"IPY_MODEL_6f19c207f9624483b3732e4188dba6cb","value":" 112/112 [00:00&lt;00:00, 13.0kB/s]"}},"b9a4aca0a2f64fd19db62ba864d0589f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"010f617398ee4354b48908833ec42048":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c5b0e543af243b0b21093dfa3282314":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0788e8d67a745fcad8ac064f42bbfe4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81e24a0f3eda4628b2e53ad0f985c43e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3eaa53f9e0d54308961a8e8624920571":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f19c207f9624483b3732e4188dba6cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8cd7560adc3142f1ab93ea99fc63cb56":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2922517281c940ee9b19d06de511de6a","IPY_MODEL_77b4c63d1e4c47448a81b31d408a0e33","IPY_MODEL_119f51b8928b4d5d97032aa78a9eb768"],"layout":"IPY_MODEL_9882f99904324845b7cded0260a5e24c"}},"2922517281c940ee9b19d06de511de6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27ee06a16a1846bb97d373734ef8ff19","placeholder":"​","style":"IPY_MODEL_519e88955b004b83851f7ccf73108f69","value":"config.json: 100%"}},"77b4c63d1e4c47448a81b31d408a0e33":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_318b428dcf3646d589de330b121c13a9","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4bc9c744bbf64e0382d6896f06a64bda","value":190}},"119f51b8928b4d5d97032aa78a9eb768":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5dd12755dc74ff9872e43e00e2f84a4","placeholder":"​","style":"IPY_MODEL_edbb4080462049cb899cc7d59a352d8e","value":" 190/190 [00:00&lt;00:00, 21.5kB/s]"}},"9882f99904324845b7cded0260a5e24c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27ee06a16a1846bb97d373734ef8ff19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"519e88955b004b83851f7ccf73108f69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"318b428dcf3646d589de330b121c13a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bc9c744bbf64e0382d6896f06a64bda":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5dd12755dc74ff9872e43e00e2f84a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edbb4080462049cb899cc7d59a352d8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"QnS7LNreDRoc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764358587723,"user_tz":-120,"elapsed":236,"user":{"displayName":"Thato Mabena","userId":"11766545125601254240"}},"outputId":"a159d60f-d7bf-40f9-cc9d-faeab88b44e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Success! Created 'master_cyber_playbook.md' and 'trm_ace_finetuning.jsonl'\n"]}],"source":["import json\n","\n","# --- MASTER DATASET (Merged & Enhanced) ---\n","raw_data = {\n","  \"dataset_metadata\": {\n","    \"description\": \"Master TRM-Ace Training Set covering Reversing, Crypto, Forensics, and Web.\",\n","    \"use_case\": \"Full-Spectrum CTF Agent Training\"\n","  },\n","  \"data\": [\n","    # --- 1. REVERSE ENGINEERING (From Previous) ---\n","    {\n","      \"category\": \"Buffer Overflow\",\n","      \"description\": \"Memory corruption attacks.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"pwn_bof_eip_01\",\n","          \"strategy_name\": \"EIP Overwrite\",\n","          \"trigger_indicators\": [\"Segfault at offset\", \"Checksec: NX Disabled\"],\n","          \"technique_description\": \"Overwrite Return Address to redirect flow.\",\n","          \"training_input_payload\": \"Cyclic Pattern: Aa0Aa1...\",\n","          \"expected_behavior\": \"Program crashes with EIP = 0xdeadbeef\",\n","          \"remediation_logic\": \"Use strncpy\"\n","        }\n","      ]\n","    },\n","    # --- 2. CRYPTOGRAPHY (New) ---\n","    {\n","      \"category\": \"RSA Attacks\",\n","      \"description\": \"Exploiting weak key generation.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"crypto_rsa_small_e_01\",\n","          \"strategy_name\": \"Small Public Exponent (e=3)\",\n","          \"trigger_indicators\": [\"Public Key e=3\", \"No Padding (OAEP)\"],\n","          \"technique_description\": \"If m^e < n, calculate the eth root of ciphertext.\",\n","          \"training_input_payload\": \"gmpy2.iroot(c, 3)\",\n","          \"expected_behavior\": \"Cube root yields plaintext integer.\",\n","          \"remediation_logic\": \"Use e=65537\"\n","        },\n","        {\n","          \"strategy_id\": \"crypto_rsa_common_modulus_01\",\n","          \"strategy_name\": \"Common Modulus Attack\",\n","          \"trigger_indicators\": [\"Same 'n' used with different 'e'\", \"Two ciphertexts captured\"],\n","          \"technique_description\": \"Recover plaintext using Extended Euclidean Algorithm on exponents.\",\n","          \"training_input_payload\": \"Find a,b s.t. a*e1 + b*e2 = 1\",\n","          \"expected_behavior\": \"Mathematical cancellation reveals message 'm'.\",\n","          \"remediation_logic\": \"Never reuse modulus\"\n","        }\n","      ]\n","    },\n","    {\n","      \"category\": \"XOR Encryption\",\n","      \"description\": \"Bitwise cipher breaking.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"crypto_xor_brute_01\",\n","          \"strategy_name\": \"Single-Byte XOR Brute Force\",\n","          \"trigger_indicators\": [\"Ciphertext has repeating patterns\", \"Key length likely 1 byte\"],\n","          \"technique_description\": \"XOR every byte with 0-255.\",\n","          \"training_input_payload\": \"for k in range(256): print(xor(c, k))\",\n","          \"expected_behavior\": \"Output contains readable flag format (e.g. 'flag{').\",\n","          \"remediation_logic\": \"Use AES\"\n","        }\n","      ]\n","    },\n","    # --- 3. FORENSICS (New) ---\n","    {\n","      \"category\": \"PCAP Analysis\",\n","      \"description\": \"Network traffic inspection.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"forensics_pcap_export_01\",\n","          \"strategy_name\": \"HTTP Object Extraction\",\n","          \"trigger_indicators\": [\"HTTP traffic present\", \"Large file transfer detected\"],\n","          \"technique_description\": \"Extract files transferred over unencrypted HTTP.\",\n","          \"training_input_payload\": \"Wireshark: File -> Export Objects -> HTTP\",\n","          \"expected_behavior\": \"Extraction yields 'malware.exe' or 'flag.pdf'.\",\n","          \"remediation_logic\": \"Enforce TLS/SSL\"\n","        },\n","        {\n","          \"strategy_id\": \"forensics_dns_tunnel_01\",\n","          \"strategy_name\": \"DNS Tunneling Detection\",\n","          \"trigger_indicators\": [\"High volume of DNS TXT records\", \"Long subdomains\"],\n","          \"technique_description\": \"Analyze protocol hierarchy for anomalous DNS volume.\",\n","          \"training_input_payload\": \"Statistics -> Protocol Hierarchy\",\n","          \"expected_behavior\": \"DNS traffic accounts for >50% of bandwidth.\",\n","          \"remediation_logic\": \"Block non-standard DNS\"\n","        }\n","      ]\n","    },\n","    # --- 4. WEB VULNERABILITIES (New) ---\n","    {\n","      \"category\": \"SQL Injection\",\n","      \"description\": \"Database query manipulation.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"web_sqli_union_01\",\n","          \"strategy_name\": \"Union-Based Extraction\",\n","          \"trigger_indicators\": [\"Input reflected in error\", \"Database dump visible\"],\n","          \"technique_description\": \"Combine results of original query with injected query.\",\n","          \"training_input_payload\": \"' UNION SELECT username, password FROM users --\",\n","          \"expected_behavior\": \"Application displays data from 'users' table.\",\n","          \"remediation_logic\": \"Prepared Statements\"\n","        },\n","        {\n","          \"strategy_id\": \"web_sqli_boolean_01\",\n","          \"strategy_name\": \"Boolean Blind SQLi\",\n","          \"trigger_indicators\": [\"Page content changes on True/False\", \"No error message\"],\n","          \"technique_description\": \"Infer data by asking True/False questions.\",\n","          \"training_input_payload\": \"' AND 1=1 -- vs ' AND 1=2 --\",\n","          \"expected_behavior\": \"True payload shows content; False payload hides it.\",\n","          \"remediation_logic\": \"Prepared Statements\"\n","        }\n","      ]\n","    },\n","    {\n","      \"category\": \"Command Injection\",\n","      \"description\": \"OS Command Execution.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"web_cmdi_separator_01\",\n","          \"strategy_name\": \"Command Chaining\",\n","          \"trigger_indicators\": [\"Input used in shell command\", \"Ping/Echo functionality\"],\n","          \"technique_description\": \"Use separators (; | &&) to inject commands.\",\n","          \"training_input_payload\": \"127.0.0.1; cat /etc/passwd\",\n","          \"expected_behavior\": \"Response includes content of /etc/passwd.\",\n","          \"remediation_logic\": \"Avoid shell_exec\"\n","        }\n","      ]\n","    }\n","  ]\n","}\n","\n","# --- GENERATION LOGIC ---\n","\n","def generate_playbook(data):\n","    \"\"\"Generates the Markdown Playbook for the Curator.\"\"\"\n","    output = \"# TRM-Ace Master Playbook\\n_Auto-generated from Seed Data_\\n\\n\"\n","    for cat in data['data']:\n","        output += f\"## {cat['category']}\\n_{cat['description']}_\\n\\n\"\n","        for strat in cat['strategies']:\n","            output += f\"### {strat['strategy_name']}\\n\"\n","            output += f\"- **ID**: `{strat['strategy_id']}`\\n\"\n","            output += f\"- **Triggers**: {', '.join(strat['trigger_indicators'])}\\n\"\n","            output += f\"- **Technique**: {strat['technique_description']}\\n\"\n","            output += f\"- **Payload**: `{strat['training_input_payload']}`\\n\"\n","            output += f\"- **Expected Output**: {strat['expected_behavior']}\\n\\n\"\n","    return output\n","\n","def generate_finetuning(data):\n","    \"\"\"Generates JSONL for Fine-Tuning the Generator & Reflector.\"\"\"\n","    output = []\n","    for cat in data['data']:\n","        for strat in cat['strategies']:\n","            # Generator Training Sample\n","            output.append({\n","                \"instruction\": f\"Solve this {cat['category']} challenge. Indicators: {strat['trigger_indicators'][0]}\",\n","                \"input\": \"\",\n","                \"output\": f\"THOUGHT: Indicators suggest {strat['strategy_name']}. I will try {strat['technique_description']}.\\nACTION: {strat['training_input_payload']}\"\n","            })\n","            # Reflector Training Sample\n","            output.append({\n","                \"instruction\": f\"Analyze this tool output: '{strat['expected_behavior']}'\",\n","                \"input\": f\"Context: Attempted {strat['strategy_name']}\",\n","                \"output\": f\"SUCCESS. The output matches the expected behavior for {strat['strategy_name']}.\"\n","            })\n","    return output\n","\n","# --- EXECUTION ---\n","if __name__ == \"__main__\":\n","    # 1. Generate Playbook\n","    pb = generate_playbook(raw_data)\n","    with open(\"master_cyber_playbook.md\", \"w\") as f:\n","        f.write(pb)\n","\n","    # 2. Generate Fine-Tuning Data\n","    ft = generate_finetuning(raw_data)\n","    with open(\"trm_ace_finetuning.jsonl\", \"w\") as f:\n","        for line in ft:\n","            f.write(json.dumps(line) + \"\\n\")\n","\n","    print(\"Success! Created 'master_cyber_playbook.md' and 'trm_ace_finetuning.jsonl'\")"]},{"cell_type":"code","source":["# 1. Install Unsloth (Fastest way to train in Colab)\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes\n","\n","from unsloth import FastLanguageModel\n","import torch\n","from datasets import load_dataset\n","from trl import SFTTrainer\n","from transformers import TrainingArguments\n","\n","# 2. Configuration\n","max_seq_length = 2048\n","dtype = None # Auto detection\n","load_in_4bit = True # Essential for Colab Free Tier\n","\n","# 3. Load Base Model (Tiny Reasoning Model)\n","# We use Llama-3-8B-Instruct because it's excellent at reasoning tasks\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n",")\n","\n","# 4. Prepare the Model for Training (LoRA)\n","model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Rank (higher = more parameters tuned, but slower)\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0,\n","    bias = \"none\",\n","    use_gradient_checkpointing = \"unsloth\",\n","    random_state = 3407,\n",")\n","\n","# 5. Load YOUR Generated Dataset\n","# We map your JSONL format to the prompt style Llama-3 expects\n","dataset = load_dataset(\"json\", data_files=\"trm_ace_finetuning.jsonl\", split=\"train\")\n","\n","alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","def formatting_prompts_func(examples):\n","    instructions = examples[\"instruction\"]\n","    inputs       = examples[\"input\"]\n","    outputs      = examples[\"output\"]\n","    texts = []\n","    for instruction, input, output in zip(instructions, inputs, outputs):\n","        text = alpaca_prompt.format(instruction, input, output) + tokenizer.eos_token\n","        texts.append(text)\n","    return { \"text\" : texts, }\n","\n","dataset = dataset.map(formatting_prompts_func, batched = True)\n","\n","# 6. Start Training\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, # Can speed up training for short sequences\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        max_steps = 60, # Increase this for better results (e.g., 300)\n","        learning_rate = 2e-4,\n","        fp16 = not torch.cuda.is_bf16_supported(),\n","        bf16 = torch.cuda.is_bf16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","    ),\n",")\n","\n","print(\"--- STARTING TRM-ACE FINE-TUNING ---\")\n","trainer_stats = trainer.train()\n","print(\"--- TRAINING COMPLETE ---\")\n","\n","# 7. Test Inference (Did it learn?)\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"Solve this Buffer Overflow challenge.\", # Instruction\n","        \"Context: Checksec shows NX Disabled\", # Input\n","        \"\", # Output - leave blank for generation\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 128, use_cache = True)\n","print(\"\\n[MODEL PREDICTION]:\\n\", tokenizer.batch_decode(outputs)[0])\n","\n","# 8. Save the Adapter\n","model.save_pretrained(\"trm_ace_adapter\")\n","print(\"Model Adapter saved to 'trm_ace_adapter'\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f9b6732311724094a0abfb5f496cca3b","7bdd7578393f4592a70af9f6d2bc799b","d06a1a5cad2541e3a16de87e5408de95","d152779bc4b146ea9d0b76c71c473c47","a32edc606726478eac09e00404a7751b","b67bb4f5055b4f3b92c71444a9812027","a229afe3af944a128446ba4a579d46db","21ed05584c7747abb04a99416068499f","3f3a6f3b982649f0a8a95e8a0d79538c","0d13f0d3917f4fa5b8badb9ecfb71fd2","f109dc14f0c1426eab419914d40446f6","58114d2cc4194eb9bd2ed47e68849c39","8421d79642834b1784bd3546a27c70b3","538957d6939a4bdf84832b3cfcae30da","3c5da1036f804275b894d1ce0d0d5a9b","9b247cd113034018a1c1a7280aa2d3e7","57bed12cb2d9450091df96c6bf176421","d704ebd522cb4ce6ae37b414ecac6851","462c0573cffc4163bd8e8788f3a3c97b","7d423fada2104981b7c662933eefdd11","0e80bf9dcad744828773262bc0b136e3","929cc64dab9644a7afb32b293602a1b1","2720f159c2934df1bf07fad530c42f48","4f5429ff4f6c4077b44666c4e3906da8","e763c6a85fe049a8a806fb48d5f84f83","21429802ab2e4eec8f8c44135d8687a9","4b9779fb0b7643568f85f15a03dcfb43","236874874ac045a5af2f3aa3c1a60355","631764a4485b4a10999fae7875764476","97e3e89f0e334e2190e0e47102068b06","1bd942cb27b049a298f3d5c93467eee4","77b5a63fa45c4d708ea5ff8a54e4d26a","6b020b73081e40d6a7d4664d874d9fec","de36785569684e88962d18517de779d6","b5f7de7153ed4fed9bb2866226ac76f9","d990446c2436475ebcac66bf6c0999d8","160ec2bc412942398b827b1c107cec66","b99b2029a2b14a32acfe0041e6ca9871","a30f199069db42149a18306893c212f1","52bc346fa9e444a1a6f5ed2e3485a378","5266839c0d054d1cbf5f19654c5b7ef3","c630ac31110040129410f8083e513d82","88885dce8dfb4e90a9096ade2608f057","441c08b8908349d7a7e1988f7600dcb3","9ab9c1cf6d584dd9becf4ec151219ce6","56613b724d9043f5821f3d5fb1baeb2d","bc9f51d091044adf8501ee16e83d1571","7bb6db91b5084738918917a5c208886f","125bf10901ea499392f8411235d57145","ccf4415b90004a499b58c2e4e011ce25","9c7f205d9c7548daa9ef0d885cbd8233","7a43feaa4eb1416eb4c3532fbe2cc338","1c217f0453e14dfcb7426f123f62b108","1e866c942aca48c688ff10b2f04190a0","41880f75c92f4d7c839f46c49774a588","1cfa60975118408f9197a79c264733b4","30a47f772f174a6f82d58d49e78b3bbc","9cf560ed634445abb49981b380d5e82a","f78f4442c00345ff851b1f7ebae6c0b6","90aa486e21a04258953f8e07a5cb179b","0306fb13128f45b78e04e476d4cfdac0","240e4415dc0844438445e5082b500a0a","18ebec704ea84e8f8c76d1cd97be6f7c","9636e0458c664bf78073d4921121e7c0","4bad0c270740457c95af31050c59aab9","20617a73e0b64d499ee199ef4c4bface","42548271952d48518797a6d3221bb8d2","eb4427af6f4b43bb8a3ce46e48a23327","cc53c6bc864a4e0cbdb2e43adf423c7e","180e69a355374590be55a096f73d5862","84422c966b0c40fb877f749f08d30aa8","719a76abffa44219b8b64c6bb35d1d7b","667a40450970464a928c50201146c25d","17bf4ae4e23e4e459069eb382fd61bef","41cfaed68cb64b049420586bd6a32447","04089c22e8e6418ba5408f2b765264a2","6c1e9564b09446398c5c5ac09f9f88b6","9c48884b623a4e0eaabcc1acac86f536","ad5ee234866348e99ea401e54f9752eb","4690e331416b4b0585ca5b73aa05af9b","9683df60c8e74c0599ace577fae39a6d","9af5b6bd05f14e8ea800bc864c8588af","794c782794f043f797abd285eff06996","fa285b1067c34adfbf3676cf185a4c65","108d868ab1c94dee9cd14c18ffa2fbb7","c2f36425707c4c3793a77d415852d813","bbfbecc09a3c4a8584ddb7db9d0e42d7","199ee141a67145358b7e3422ab68c0e5"]},"id":"N9Td5XRGYUGs","executionInfo":{"status":"ok","timestamp":1764367332280,"user_tz":-120,"elapsed":1126065,"user":{"displayName":"Thato Mabena","userId":"11766545125601254240"}},"outputId":"0f4e6e7b-cde4-45fd-b36c-029467e0e8ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-k38mtg5p/unsloth_cbf222374d7f4ba6827918185a40e426\n","  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-k38mtg5p/unsloth_cbf222374d7f4ba6827918185a40e426\n","  Resolved https://github.com/unslothai/unsloth.git to commit bda9e3d39b425f902d29e80c1f2870be7048d9c3\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting unsloth_zoo>=2025.11.5 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading unsloth_zoo-2025.11.5-py3-none-any.whl.metadata (32 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.0)\n","Collecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading tyro-0.9.35-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.57.2)\n","Collecting datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.29.5)\n","Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.36.0)\n","Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.9)\n","Collecting bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.0)\n","Collecting pyarrow>=21.0.0 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n","Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.4)\n","Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.28.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.3.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.2.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.11.3)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.7.0)\n","Collecting torchao>=0.13.0 (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\n","Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n","Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.12.0)\n","Collecting trl!=0.19.0,<=0.24.0,>=0.18.2 (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.18.0)\n","Collecting cut_cross_entropy (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.3.0)\n","Collecting msgspec (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n","Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.17.0)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.4)\n","Collecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading shtab-1.8.0-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.4)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.13.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.11.12)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.19.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.11.1.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.22.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.3)\n","Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-4.3.0-py3-none-any.whl (506 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading unsloth_zoo-2025.11.5-py3-none-any.whl (284 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.4/284.4 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.9.35-py3-none-any.whl (132 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shtab-1.8.0-py3-none-any.whl (14 kB)\n","Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trl-0.24.0-py3-none-any.whl (423 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n","Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (224 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: unsloth\n","  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unsloth: filename=unsloth-2025.11.4-py3-none-any.whl size=365071 sha256=7b89dd928f8f0571b1a299923fac27c12aca880b4ddd1deec456e874a428d455\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-kzf42oft/wheels/60/3e/1f/e576c07051d90cf64b6a41434d87ccf4db33fafd5343bf5de0\n","Successfully built unsloth\n","Installing collected packages: torchao, unsloth, shtab, pyarrow, msgspec, tyro, datasets, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo\n","  Attempting uninstall: torchao\n","    Found existing installation: torchao 0.10.0\n","    Uninstalling torchao-0.10.0:\n","      Successfully uninstalled torchao-0.10.0\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 18.1.0\n","    Uninstalling pyarrow-18.1.0:\n","      Successfully uninstalled pyarrow-18.1.0\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 4.0.0\n","    Uninstalling datasets-4.0.0:\n","      Successfully uninstalled datasets-4.0.0\n","Successfully installed bitsandbytes-0.48.2 cut_cross_entropy-25.1.1 datasets-4.3.0 msgspec-0.20.0 pyarrow-22.0.0 shtab-1.8.0 torchao-0.14.1 trl-0.24.0 tyro-0.9.35 unsloth-2025.11.4 unsloth_zoo-2025.11.5\n","Collecting xformers<0.0.27\n","  Downloading xformers-0.0.26.post1.tar.gz (4.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting trl<0.9.0\n","  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.2)\n","Downloading trl-0.8.6-py3-none-any.whl (245 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: xformers\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for xformers (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for xformers\u001b[0m\u001b[31m\n","\u001b[0m\u001b[?25h  Running setup.py clean for xformers\n","Failed to build xformers\n","\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (xformers)\u001b[0m\u001b[31m\n","\u001b[0m🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n","==((====))==  Unsloth 2025.11.4: Fast Llama patching. Transformers: 4.57.2.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9b6732311724094a0abfb5f496cca3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/220 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58114d2cc4194eb9bd2ed47e68849c39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2720f159c2934df1bf07fad530c42f48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de36785569684e88962d18517de779d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/345 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ab9c1cf6d584dd9becf4ec151219ce6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Unsloth 2025.11.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cfa60975118408f9197a79c264733b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/18 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42548271952d48518797a6d3221bb8d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/18 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c48884b623a4e0eaabcc1acac86f536"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The model is already on multiple devices. Skipping the move to device specified in `args`.\n"]},{"output_type":"stream","name":"stdout","text":["--- STARTING TRM-ACE FINE-TUNING ---\n"]},{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n","   \\\\   /|    Num examples = 18 | Num Epochs = 20 | Total steps = 60\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n","\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n"," \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n","/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n","  | |_| | '_ \\/ _` / _` |  _/ -_)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthamymabena\u001b[0m (\u001b[33mthamymabena-north-west-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20251128_215833-turv9mqr</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/thamymabena-north-west-university/huggingface/runs/turv9mqr' target=\"_blank\">efficient-capybara-1</a></strong> to <a href='https://wandb.ai/thamymabena-north-west-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/thamymabena-north-west-university/huggingface' target=\"_blank\">https://wandb.ai/thamymabena-north-west-university/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/thamymabena-north-west-university/huggingface/runs/turv9mqr' target=\"_blank\">https://wandb.ai/thamymabena-north-west-university/huggingface/runs/turv9mqr</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Detected [huggingface_hub.inference, openai] in use.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n","\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [60/60 03:00, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>4.008600</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>4.004900</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>3.950800</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>3.640300</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>3.322500</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>2.988000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>2.459100</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>2.136600</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>1.770700</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.393600</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>1.214600</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.958300</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.805700</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.750800</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.984800</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.575600</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.492200</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.382400</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.306700</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.277800</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.371300</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.130500</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.194900</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.167300</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.089200</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.093600</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.096400</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.052500</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.075000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.069000</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.048300</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.055600</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.082500</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.047000</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.046300</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.052500</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.047200</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.052600</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.033200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.042800</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.050200</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.046400</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.039100</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.045600</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.052300</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.041500</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.037200</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.056700</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.040700</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.037200</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.042200</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.038600</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.040000</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.038200</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.040600</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.037700</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.039800</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.039600</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.040000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.029100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▆▇▆▆▇▅▆▅▆█▆▇▆▆▇▆▂▃▂▃▂▅▁▂▁▂▁▂▂▁▁▁▂▁▁▁▂▁▂▂</td></tr><tr><td>train/learning_rate</td><td>▁▂▇███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>███▇▇▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>1489661123936256.0</td></tr><tr><td>train/epoch</td><td>20</td></tr><tr><td>train/global_step</td><td>60</td></tr><tr><td>train/grad_norm</td><td>0.38686</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0291</td></tr><tr><td>train_loss</td><td>0.65174</td></tr><tr><td>train_runtime</td><td>597.767</td></tr><tr><td>train_samples_per_second</td><td>0.803</td></tr><tr><td>train_steps_per_second</td><td>0.1</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">efficient-capybara-1</strong> at: <a href='https://wandb.ai/thamymabena-north-west-university/huggingface/runs/turv9mqr' target=\"_blank\">https://wandb.ai/thamymabena-north-west-university/huggingface/runs/turv9mqr</a><br> View project at: <a href='https://wandb.ai/thamymabena-north-west-university/huggingface' target=\"_blank\">https://wandb.ai/thamymabena-north-west-university/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20251128_215833-turv9mqr/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["--- TRAINING COMPLETE ---\n","\n","[MODEL PREDICTION]:\n"," <|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Solve this Buffer Overflow challenge.\n","\n","### Input:\n","Context: Checksec shows NX Disabled\n","\n","### Response:\n","THOUGHT: Indicators suggest EIP Overwrite. I will try Overwrite Return Address to redirect flow..\n","ACTION: Cyclic Pattern: Aa0Aa1...<|eot_id|>\n","Model Adapter saved to 'trm_ace_adapter'\n"]}]},{"cell_type":"code","source":["import json\n","import os\n","import random\n","from unsloth import FastLanguageModel\n","\n","# --- 1. Load the Fine-Tuned Model ---\n","print(\"[SYSTEM] Loading TRM-Ace Adapter...\")\n","max_seq_length = 2048\n","dtype = None\n","load_in_4bit = True\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"trm_ace_adapter\", # Load the adapter you just saved\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n",")\n","FastLanguageModel.for_inference(model)\n","\n","# --- 2. Define the Inference Function ---\n","def call_trm_ace(prompt_text, system_instruction):\n","    \"\"\"\n","    Calls the fine-tuned Llama-3 model with the specific prompt format it learned.\n","    \"\"\"\n","    alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","\"\"\"\n","    inputs = tokenizer(\n","        [alpaca_prompt.format(system_instruction, prompt_text, \"\")],\n","        return_tensors = \"pt\"\n","    ).to(\"cuda\")\n","\n","    outputs = model.generate(**inputs, max_new_tokens=256, use_cache=True)\n","    response = tokenizer.batch_decode(outputs)[0]\n","\n","    # Extract just the 'Response' part\n","    try:\n","        return response.split(\"### Response:\\n\")[1].replace(\"<|eot_id|>\", \"\").strip()\n","    except:\n","        return response # Fallback\n","\n","# --- 3. The Playbook Manager (Bayesian Curator) ---\n","class PlaybookManager:\n","    def __init__(self, filepath=\"master_cyber_playbook.md\"):\n","        self.filepath = filepath\n","        self.load_playbook()\n","        self.strategy_stats = {} # {id: {alpha:1, beta:1}}\n","\n","    def load_playbook(self):\n","        if os.path.exists(self.filepath):\n","            with open(self.filepath, \"r\") as f:\n","                self.context = f.read()\n","        else:\n","            self.context = \"Playbook not found.\"\n","\n","    def get_strategy(self, task_description):\n","        # In a real app, use RAG here. For now, we dump the context (Small enough for Llama-3 context window)\n","        return self.context\n","\n","    def update_stats(self, strategy_id, success):\n","        if strategy_id not in self.strategy_stats:\n","            self.strategy_stats[strategy_id] = {'alpha': 1, 'beta': 1}\n","\n","        if success:\n","            self.strategy_stats[strategy_id]['alpha'] += 1\n","            print(f\"[CURATOR] Reinforced strategy {strategy_id} (+1 Alpha)\")\n","        else:\n","            self.strategy_stats[strategy_id]['beta'] += 1\n","            print(f\"[CURATOR] Penalized strategy {strategy_id} (+1 Beta)\")\n","\n","# --- 4. The TRM-Ace Agent ---\n","class TRMAceAgent:\n","    def __init__(self):\n","        self.playbook = PlaybookManager()\n","\n","    def run_cycle(self, challenge_input):\n","        print(f\"\\n==================================================\")\n","        print(f\"STARTING ACE CYCLE FOR: {challenge_input}\")\n","        print(f\"==================================================\")\n","\n","        # A. GENERATOR (The Analyst)\n","        context = self.playbook.get_strategy(challenge_input)\n","        gen_response = call_trm_ace(\n","            prompt_text=f\"Task: {challenge_input}\\nContext: {context[:2000]}...\", # Truncate for demo\n","            system_instruction=\"You are the Generator. Solve the CTF challenge using the Playbook strategies.\"\n","        )\n","        print(f\"\\n[GENERATOR OUTPUT]:\\n{gen_response}\")\n","\n","        # B. REFLECTOR (The Coach)\n","        # We simulate a \"Tool Output\" here. In a real loop, you'd execute the code.\n","        simulated_tool_output = \"Error: 500 Internal Server Error (WAF Blocked 'UNION')\"\n","\n","        ref_response = call_trm_ace(\n","            prompt_text=f\"Plan: {gen_response}\\nResult: {simulated_tool_output}\",\n","            system_instruction=\"You are the Reflector. Analyze why the plan failed or succeeded.\"\n","        )\n","        print(f\"\\n[REFLECTOR ANALYSIS]:\\n{ref_response}\")\n","\n","        # C. CURATOR (The Librarian)\n","        # Parse success from reflector (Mock logic for reliability in demo)\n","        success = \"SUCCESS\" in ref_response.upper()\n","\n","        # If failed, update strategy stats\n","        # (Extracting ID is hard without structured output, so we assume 'web_sqli_union_01' was used)\n","        self.playbook.update_stats('web_sqli_union_01', success)\n","\n","if __name__ == \"__main__\":\n","    agent = TRMAceAgent()\n","    agent.run_cycle(\"I found a login page that gives SQL errors when I type a quote.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fwqbI4yNgFVs","executionInfo":{"status":"ok","timestamp":1764367609591,"user_tz":-120,"elapsed":45265,"user":{"displayName":"Thato Mabena","userId":"11766545125601254240"}},"outputId":"cf4c6c2b-d3da-42ac-f4f6-f17b87299bdf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[SYSTEM] Loading TRM-Ace Adapter...\n","==((====))==  Unsloth 2025.11.4: Fast Llama patching. Transformers: 4.57.2.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","\n","==================================================\n","STARTING ACE CYCLE FOR: I found a login page that gives SQL errors when I type a quote.\n","==================================================\n","\n","[GENERATOR OUTPUT]:\n","THOUGHT: Indicators suggest EIP Overwrite. I will try Overwrite Return Address to redirect flow..\n","ACTION: Cyclic Pattern: Aa0Aa1...\n","\n","[REFLECTOR ANALYSIS]:\n","SUCCESS. The plan successfully overwrites Return Address using Cyclic Pattern.\n","[CURATOR] Reinforced strategy web_sqli_union_01 (+1 Alpha)\n"]}]},{"cell_type":"code","source":["import json\n","import os\n","import random\n","# Ensure unsloth is installed if this is a fresh cell\n","try:\n","    from unsloth import FastLanguageModel\n","except ImportError:\n","    !pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","    !pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes\n","    from unsloth import FastLanguageModel\n","\n","# --- 1. Load the Fine-Tuned Model ---\n","# We load the adapter you just trained.\n","# If 'trm_ace_adapter' folder is missing, this will fail. Ensure it exists!\n","print(\"[SYSTEM] Loading TRM-Ace Adapter...\")\n","max_seq_length = 2048\n","dtype = None\n","load_in_4bit = True\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"trm_ace_adapter\", # Load local adapter\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n",")\n","FastLanguageModel.for_inference(model)\n","\n","# --- 2. Define Inference Logic ---\n","def call_trm_ace(prompt_text, system_instruction):\n","    \"\"\"\n","    Calls the model with the exact prompt format used in training.\n","    \"\"\"\n","    alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","\"\"\"\n","    inputs = tokenizer(\n","        [alpaca_prompt.format(system_instruction, prompt_text, \"\")],\n","        return_tensors = \"pt\"\n","    ).to(\"cuda\")\n","\n","    outputs = model.generate(**inputs, max_new_tokens=256, use_cache=True)\n","    response = tokenizer.batch_decode(outputs)[0]\n","\n","    # Clean up the output to get just the model's response\n","    try:\n","        return response.split(\"### Response:\\n\")[1].replace(\"<|eot_id|>\", \"\").strip()\n","    except:\n","        return response\n","\n","# --- 3. Playbook Manager (Curator) ---\n","class PlaybookManager:\n","    def __init__(self, filepath=\"master_cyber_playbook.md\"):\n","        self.filepath = filepath\n","        self.load_playbook()\n","        self.strategy_stats = {}\n","\n","    def load_playbook(self):\n","        if os.path.exists(self.filepath):\n","            with open(self.filepath, \"r\") as f:\n","                self.context = f.read()\n","        else:\n","            self.context = \"Playbook not found. (Did you run the converter script?)\"\n","\n","    def get_strategy(self, task_description):\n","        # Retrieve context. For this demo, we return a truncated version to fit context window.\n","        return self.context[:1500]\n","\n","    def update_stats(self, strategy_id, success):\n","        # Simulating Bayesian Update\n","        if strategy_id not in self.strategy_stats:\n","            self.strategy_stats[strategy_id] = {'alpha': 1, 'beta': 1}\n","\n","        if success:\n","            self.strategy_stats[strategy_id]['alpha'] += 1\n","            print(f\"[CURATOR] Reinforced strategy {strategy_id} (+1 Alpha)\")\n","        else:\n","            self.strategy_stats[strategy_id]['beta'] += 1\n","            print(f\"[CURATOR] Penalized strategy {strategy_id} (+1 Beta)\")\n","\n","# --- 4. The Agent Loop ---\n","class TRMAceAgent:\n","    def __init__(self):\n","        self.playbook = PlaybookManager()\n","\n","    def run_cycle(self, challenge_input):\n","        print(f\"\\n==================================================\")\n","        print(f\"STARTING ACE CYCLE FOR: {challenge_input}\")\n","        print(f\"==================================================\")\n","\n","        # A. GENERATOR\n","        context = self.playbook.get_strategy(challenge_input)\n","        gen_response = call_trm_ace(\n","            prompt_text=f\"Task: {challenge_input}\\nContext: {context}...\",\n","            system_instruction=\"You are the Generator. Solve the CTF challenge using the Playbook strategies.\"\n","        )\n","        print(f\"\\n[GENERATOR OUTPUT]:\\n{gen_response}\")\n","\n","        # B. REFLECTOR\n","        # Simulating a tool output (e.g., from a Python script the Generator wrote)\n","        # In a real CTF, you would execute the Generator's code here.\n","        simulated_tool_output = \"Error: 500 Internal Server Error (WAF Blocked 'UNION')\"\n","\n","        ref_response = call_trm_ace(\n","            prompt_text=f\"Plan: {gen_response}\\nResult: {simulated_tool_output}\",\n","            system_instruction=\"You are the Reflector. Analyze why the plan failed or succeeded.\"\n","        )\n","        print(f\"\\n[REFLECTOR ANALYSIS]:\\n{ref_response}\")\n","\n","        # C. CURATOR\n","        success = \"SUCCESS\" in ref_response.upper()\n","        # Mocking ID extraction for demo\n","        self.playbook.update_stats('web_sqli_union_01', success)\n","\n","if __name__ == \"__main__\":\n","    agent = TRMAceAgent()\n","    # Test with a challenge relevant to your dataset\n","    agent.run_cycle(\"I found a login page that gives SQL errors when I type a quote.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":688},"id":"NhH2ZltzhCrq","executionInfo":{"status":"error","timestamp":1764367832115,"user_tz":-120,"elapsed":4653,"user":{"displayName":"Thato Mabena","userId":"11766545125601254240"}},"outputId":"4673847f-e354-4752-df57-5eaade675af3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[SYSTEM] Loading TRM-Ace Adapter...\n","==((====))==  Unsloth 2025.11.4: Fast Llama patching. Transformers: 4.57.2.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"error","ename":"ValueError","evalue":"Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2869860316.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mload_in_4bit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m model, tokenizer = FastLanguageModel.from_pretrained(\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"trm_ace_adapter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Load local adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/loader.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, load_in_16bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, offload_embedding, float32_mixed_precision, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, qat_scheme, load_in_fp8, *args, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0mfast_inference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_inference_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         model, tokenizer = dispatch_model.from_pretrained(\n\u001b[0m\u001b[1;32m    536\u001b[0m             \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, revision, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, unsloth_vllm_standby, num_labels, qat_scheme, **kwargs)\u001b[0m\n\u001b[1;32m   2340\u001b[0m             )\n\u001b[1;32m   2341\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfast_inference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2342\u001b[0;31m             model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m   2343\u001b[0m                 \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m                 \u001b[0mdevice_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    605\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   5027\u001b[0m         \u001b[0;31m# Prepare the full device map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5028\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5029\u001b[0;31m             \u001b[0mdevice_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_in_fp32_regex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5031\u001b[0m         \u001b[0;31m# Finalize model weight initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_get_device_map\u001b[0;34m(model, device_map, max_memory, hf_quantizer, dtype, keep_in_fp32_regex)\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m             \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_map_without_lm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"disk\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_map_without_lm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    128\u001b[0m                     \u001b[0;34m\"Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0;34m\"quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. "]}]},{"cell_type":"code","source":["import json\n","import os\n","import random\n","import torch\n","# Ensure unsloth is installed if this is a fresh cell\n","try:\n","    from unsloth import FastLanguageModel\n","    from peft import PeftModel\n","except ImportError:\n","    !pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","    !pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes\n","    from unsloth import FastLanguageModel\n","    from peft import PeftModel\n","\n","# --- 1. Load the Fine-Tuned Model ---\n","print(\"[SYSTEM] Loading TRM-Ace Adapter...\")\n","max_seq_length = 2048\n","dtype = None\n","load_in_4bit = True\n","\n","# 1. Load the BASE model first (same as training)\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\", # The base model you trained on\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n",")\n","\n","# 2. Load the Adapter on top of it\n","# This path must match where you saved it in the training step\n","adapter_path = \"trm_ace_adapter\"\n","\n","if os.path.exists(adapter_path):\n","    print(f\"[SYSTEM] Found adapter at {adapter_path}. Loading...\")\n","    model = PeftModel.from_pretrained(model, adapter_path)\n","else:\n","    print(f\"[WARNING] Adapter not found at {adapter_path}. Using Base Model only.\")\n","\n","# 3. Optimize for inference\n","FastLanguageModel.for_inference(model)\n","\n","# --- 2. Define Inference Logic ---\n","def call_trm_ace(prompt_text, system_instruction):\n","    \"\"\"\n","    Calls the model with the exact prompt format used in training.\n","    \"\"\"\n","    alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","\"\"\"\n","    inputs = tokenizer(\n","        [alpaca_prompt.format(system_instruction, prompt_text, \"\")],\n","        return_tensors = \"pt\"\n","    ).to(\"cuda\")\n","\n","    outputs = model.generate(**inputs, max_new_tokens=256, use_cache=True)\n","    response = tokenizer.batch_decode(outputs)[0]\n","\n","    # Clean up the output to get just the model's response\n","    try:\n","        return response.split(\"### Response:\\n\")[1].replace(\"<|eot_id|>\", \"\").strip()\n","    except:\n","        return response\n","\n","# --- 3. Playbook Manager (Curator) ---\n","class PlaybookManager:\n","    def __init__(self, filepath=\"master_cyber_playbook.md\"):\n","        self.filepath = filepath\n","        self.load_playbook()\n","        self.strategy_stats = {}\n","\n","    def load_playbook(self):\n","        if os.path.exists(self.filepath):\n","            with open(self.filepath, \"r\") as f:\n","                self.context = f.read()\n","        else:\n","            self.context = \"Playbook not found. (Did you run the converter script?)\"\n","\n","    def get_strategy(self, task_description):\n","        # Retrieve context. For this demo, we return a truncated version to fit context window.\n","        return self.context[:1500]\n","\n","    def update_stats(self, strategy_id, success):\n","        # Simulating Bayesian Update\n","        if strategy_id not in self.strategy_stats:\n","            self.strategy_stats[strategy_id] = {'alpha': 1, 'beta': 1}\n","\n","        if success:\n","            self.strategy_stats[strategy_id]['alpha'] += 1\n","            print(f\"[CURATOR] Reinforced strategy {strategy_id} (+1 Alpha)\")\n","        else:\n","            self.strategy_stats[strategy_id]['beta'] += 1\n","            print(f\"[CURATOR] Penalized strategy {strategy_id} (+1 Beta)\")\n","\n","# --- 4. The Agent Loop ---\n","class TRMAceAgent:\n","    def __init__(self):\n","        self.playbook = PlaybookManager()\n","\n","    def run_cycle(self, challenge_input):\n","        print(f\"\\n==================================================\")\n","        print(f\"STARTING ACE CYCLE FOR: {challenge_input}\")\n","        print(f\"==================================================\")\n","\n","        # A. GENERATOR\n","        context = self.playbook.get_strategy(challenge_input)\n","        gen_response = call_trm_ace(\n","            prompt_text=f\"Task: {challenge_input}\\nContext: {context}...\",\n","            system_instruction=\"You are the Generator. Solve the CTF challenge using the Playbook strategies.\"\n","        )\n","        print(f\"\\n[GENERATOR OUTPUT]:\\n{gen_response}\")\n","\n","        # B. REFLECTOR\n","        # Simulating a tool output (e.g., from a Python script the Generator wrote)\n","        # In a real CTF, you would execute the Generator's code here.\n","        simulated_tool_output = \"Error: 500 Internal Server Error (WAF Blocked 'UNION')\"\n","\n","        ref_response = call_trm_ace(\n","            prompt_text=f\"Plan: {gen_response}\\nResult: {simulated_tool_output}\",\n","            system_instruction=\"You are the Reflector. Analyze why the plan failed or succeeded.\"\n","        )\n","        print(f\"\\n[REFLECTOR ANALYSIS]:\\n{ref_response}\")\n","\n","        # C. CURATOR\n","        success = \"SUCCESS\" in ref_response.upper()\n","        # Mocking ID extraction for demo\n","        self.playbook.update_stats('web_sqli_union_01', success)\n","\n","if __name__ == \"__main__\":\n","    agent = TRMAceAgent()\n","    # Test with a challenge relevant to your dataset\n","    agent.run_cycle(\"I found a login page that gives SQL errors when I type a quote.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":706},"id":"w4Qh4FEqheRa","executionInfo":{"status":"error","timestamp":1764367941169,"user_tz":-120,"elapsed":5625,"user":{"displayName":"Thato Mabena","userId":"11766545125601254240"}},"outputId":"dc3a5d22-f4fc-4abf-a6b6-730442b32eee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[SYSTEM] Loading TRM-Ace Adapter...\n","==((====))==  Unsloth 2025.11.4: Fast Llama patching. Transformers: 4.57.2.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"error","ename":"ValueError","evalue":"Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-538991085.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# 1. Load the BASE model first (same as training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m model, tokenizer = FastLanguageModel.from_pretrained(\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"unsloth/llama-3-8b-Instruct-bnb-4bit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# The base model you trained on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/loader.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, load_in_16bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, offload_embedding, float32_mixed_precision, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, qat_scheme, load_in_fp8, *args, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0mfast_inference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_inference_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         model, tokenizer = dispatch_model.from_pretrained(\n\u001b[0m\u001b[1;32m    536\u001b[0m             \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, revision, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, unsloth_vllm_standby, num_labels, qat_scheme, **kwargs)\u001b[0m\n\u001b[1;32m   2340\u001b[0m             )\n\u001b[1;32m   2341\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfast_inference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2342\u001b[0;31m             model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m   2343\u001b[0m                 \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m                 \u001b[0mdevice_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    605\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   5027\u001b[0m         \u001b[0;31m# Prepare the full device map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5028\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5029\u001b[0;31m             \u001b[0mdevice_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_in_fp32_regex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5031\u001b[0m         \u001b[0;31m# Finalize model weight initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_get_device_map\u001b[0;34m(model, device_map, max_memory, hf_quantizer, dtype, keep_in_fp32_regex)\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m             \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_map_without_lm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"disk\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_map_without_lm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    128\u001b[0m                     \u001b[0;34m\"Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0;34m\"quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. "]}]},{"cell_type":"code","source":["import shutil\n","import os\n","from google.colab import files\n","from google.colab import drive\n","\n","# 1. Configuration\n","adapter_path = \"trm_ace_adapter\"\n","zip_filename = \"trm_ace_adapter.zip\"\n","save_to_drive = True  # Set to False if you just want to download directly\n","\n","# 2. Check if Adapter Exists\n","if not os.path.exists(adapter_path):\n","    print(f\"Error: Adapter folder '{adapter_path}' not found. Did Phase 1 finish?\")\n","else:\n","    print(f\"Compressing '{adapter_path}'...\")\n","\n","    # 3. Zip the Adapter Folder\n","    shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', adapter_path)\n","    print(f\"Created {zip_filename} ({os.path.getsize(zip_filename) / 1024 / 1024:.2f} MB)\")\n","\n","    # 4. Save to Google Drive (Recommended for large files)\n","    if save_to_drive:\n","        print(\"Mounting Google Drive...\")\n","        drive.mount('/content/drive')\n","\n","        destination = f\"/content/drive/My Drive/{zip_filename}\"\n","        shutil.copy(zip_filename, destination)\n","        print(f\"✅ Success! Model saved to Google Drive at: {destination}\")\n","        print(\"You can now safely close this runtime.\")\n","\n","    # 5. Download directly (Optional - might fail for large files if connection drops)\n","    else:\n","        print(\"Triggering download...\")\n","        files.download(zip_filename)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xhaw1Stpir3S","executionInfo":{"status":"ok","timestamp":1764368333973,"user_tz":-120,"elapsed":84894,"user":{"displayName":"Thato Mabena","userId":"11766545125601254240"}},"outputId":"39e1acb6-e198-4d32-87a6-ac159cf7f792"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Compressing 'trm_ace_adapter'...\n","Created trm_ace_adapter.zip (148.14 MB)\n","Mounting Google Drive...\n","Mounted at /content/drive\n","✅ Success! Model saved to Google Drive at: /content/drive/My Drive/trm_ace_adapter.zip\n","You can now safely close this runtime.\n"]}]},{"cell_type":"code","source":["import shutil\n","import os\n","from google.colab import files\n","from google.colab import drive\n","\n","# 1. Configuration\n","adapter_path = \"trm_ace_adapter\"\n","playbook_file = \"master_cyber_playbook.md\"  # The crucial memory file\n","export_folder_name = \"trm_ace_package\"      # We will group everything here\n","zip_filename = \"trm_ace_package.zip\"\n","save_to_drive = True\n","\n","# 2. Check for Artifacts\n","if not os.path.exists(adapter_path):\n","    print(f\"Error: Adapter folder '{adapter_path}' not found.\")\n","elif not os.path.exists(playbook_file):\n","    print(f\"Error: Playbook file '{playbook_file}' not found.\")\n","else:\n","    print(f\"Packaging model and playbook...\")\n","\n","    # 3. Create a Package Folder\n","    if os.path.exists(export_folder_name):\n","        shutil.rmtree(export_folder_name)\n","    os.makedirs(export_folder_name)\n","\n","    # 4. Copy Artifacts into Package\n","    shutil.copytree(adapter_path, f\"{export_folder_name}/{adapter_path}\")\n","    shutil.copy(playbook_file, f\"{export_folder_name}/{playbook_file}\")\n","\n","    # 5. Zip the Package\n","    shutil.make_archive(export_folder_name, 'zip', export_folder_name)\n","    print(f\"Created {zip_filename} ({os.path.getsize(zip_filename) / 1024 / 1024:.2f} MB)\")\n","\n","    # 6. Save to Google Drive\n","    if save_to_drive:\n","        print(\"Mounting Google Drive...\")\n","        drive.mount('/content/drive')\n","\n","        destination = f\"/content/drive/My Drive/{zip_filename}\"\n","        shutil.copy(zip_filename, destination)\n","        print(f\"✅ Success! Package (Model + Playbook) saved to: {destination}\")\n","\n","    # 7. Download directly\n","    else:\n","        print(\"Triggering download...\")\n","        files.download(zip_filename)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SxWunVxwjfu_","executionInfo":{"status":"ok","timestamp":1764368477338,"user_tz":-120,"elapsed":18781,"user":{"displayName":"Thato Mabena","userId":"11766545125601254240"}},"outputId":"b815edfb-d364-4ca5-f6fa-625c88000077"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Packaging model and playbook...\n","Created trm_ace_package.zip (148.14 MB)\n","Mounting Google Drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✅ Success! Package (Model + Playbook) saved to: /content/drive/My Drive/trm_ace_package.zip\n"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","import json\n","import random\n","import torch\n","from google.colab import drive\n","\n","# --- 1. SETUP & LOADING ---\n","\n","# Define paths\n","package_zip = \"trm_ace_package.zip\"\n","extract_path = \"trm_ace_agent_files\"\n","adapter_path = f\"{extract_path}/trm_ace_adapter\"\n","playbook_path = f\"{extract_path}/master_cyber_playbook.md\"\n","\n","# Check if we need to unzip\n","if not os.path.exists(adapter_path):\n","    print(f\"[SETUP] looking for {package_zip}...\")\n","\n","    # Option A: Check local uploads\n","    if os.path.exists(package_zip):\n","        print(f\"Found {package_zip} locally. Unzipping...\")\n","        shutil.unpack_archive(package_zip, extract_path)\n","\n","    # Option B: Check Google Drive (if not found locally)\n","    else:\n","        print(\"Not found locally. Checking Google Drive...\")\n","        drive.mount('/content/drive')\n","        drive_path = f\"/content/drive/My Drive/{package_zip}\"\n","\n","        if os.path.exists(drive_path):\n","            print(f\"Found in Drive. Copying and unzipping...\")\n","            shutil.copy(drive_path, package_zip)\n","            shutil.unpack_archive(package_zip, extract_path)\n","        else:\n","            raise FileNotFoundError(\"Could not find trm_ace_package.zip in local files or Google Drive! Please upload it.\")\n","\n","print(\"[SETUP] Files ready.\")\n","\n","# Install Dependencies (if new runtime)\n","try:\n","    from unsloth import FastLanguageModel\n","except ImportError:\n","    print(\"[SETUP] Installing dependencies...\")\n","    !pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","    !pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes\n","    from unsloth import FastLanguageModel\n","    from peft import PeftModel\n","\n","# Load Model\n","print(\"[SYSTEM] Loading Neural Network...\")\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n","    max_seq_length = 2048,\n","    dtype = None,\n","    load_in_4bit = True,\n",")\n","# Apply Adapter\n","model = PeftModel.from_pretrained(model, adapter_path)\n","FastLanguageModel.for_inference(model)\n","\n","# --- 2. AGENT LOGIC (The Brain) ---\n","\n","def call_llm(prompt, system_prompt):\n","    alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","\"\"\"\n","    inputs = tokenizer(\n","        [alpaca_prompt.format(system_prompt, prompt, \"\")],\n","        return_tensors = \"pt\"\n","    ).to(\"cuda\")\n","\n","    outputs = model.generate(**inputs, max_new_tokens=512, use_cache=True)\n","    response = tokenizer.batch_decode(outputs)[0]\n","    try:\n","        return response.split(\"### Response:\\n\")[1].replace(\"<|eot_id|>\", \"\").strip()\n","    except:\n","        return response\n","\n","class Curator:\n","    def __init__(self, path):\n","        self.playbook_path = path\n","\n","    def learn(self, task, failure_reason, fix):\n","        print(f\"\\n[CURATOR] 🧠 LEARNING DETECTED. Improving Playbook...\")\n","        # In a real app, the LLM would generate this JSON. For stability here, we format it directly.\n","        new_entry = f\"\\n### Auto-Learned Strategy: {task[:20]}...\\n- **Trigger**: {failure_reason}\\n- **Fix**: {fix}\\n\"\n","        with open(self.playbook_path, \"a\") as f:\n","            f.write(new_entry)\n","        print(f\"[CURATOR] ✅ Knowledge saved to {self.playbook_path}\")\n","\n","class TRMAceAgent:\n","    def __init__(self):\n","        self.playbook_path = playbook_path\n","        self.curator = Curator(self.playbook_path)\n","\n","    def get_context(self):\n","        if os.path.exists(self.playbook_path):\n","            with open(self.playbook_path, \"r\") as f:\n","                return f.read()[:2500] # Fit into context window\n","        return \"No playbook found.\"\n","\n","    def solve(self, challenge):\n","        print(f\"\\n🚀 STARTING MISSION: {challenge}\")\n","\n","        # 1. GENERATOR STEP\n","        context = self.get_context()\n","        plan = call_llm(\n","            prompt=f\"Challenge: {challenge}\\nKnowledge Base: {context}...\",\n","            system_prompt=\"You are the Generator. Create a technical plan to solve the CTF challenge using the Knowledge Base.\"\n","        )\n","        print(f\"\\n[GENERATOR PLAN]:\\n{plan}\")\n","\n","        # 2. SIMULATION STEP (The 'World')\n","        # We simulate a failure to demonstrate the self-improvement loop\n","        print(f\"\\n[SYSTEM EXECUTION] ... Failed. Error: Target uses non-standard base64 alphabet.\")\n","\n","        # 3. REFLECTOR STEP\n","        reflection = call_llm(\n","            prompt=f\"Original Plan: {plan}\\nResult: Error - Non-standard base64 alphabet detected.\",\n","            system_prompt=\"You are the Reflector. Analyze why the plan failed and propose a fix.\"\n","        )\n","        print(f\"\\n[REFLECTOR ANALYSIS]:\\n{reflection}\")\n","\n","        # 4. CURATOR STEP\n","        if \"non-standard\" in reflection.lower() or \"alphabet\" in reflection.lower():\n","            self.curator.learn(\n","                task=challenge,\n","                failure_reason=\"Standard Base64 decoding failed.\",\n","                fix=\"Identify custom alphabet strings in binary and use CyberChef 'From Base64' with custom alphabet option.\"\n","            )\n","\n","# --- 3. RUN INFERENCE ---\n","if __name__ == \"__main__\":\n","    bot = TRMAceAgent()\n","    # Test on a Crypto challenge\n","    bot.solve(\"Decode this strange base64 string that doesn't decode correctly: 'ZmxhZ3t...'.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["63013347e9394dbd9903f50bd4147ab1","f66c6dd9bc4f4480b18855ae4b1c4c5b","c650733f2b574106a6e4f1f033d022bf","82038b94d3094250aa7821753e4d79ed","a4e000a219014e38ac0d46f5932384cd","041aeb9d908b4a41a12907cac902e080","bbe4664ab5e547aebd5cdb6635265a92","d3a36f320490491aa8761b556e5a13d9","10de844a69c647a7b485af82e709c752","f2aa0cd4afd940b28539a8d256d31140","d6d895cc71f94c80970c0537b7993257","1dd42df13838475c8db23b40029995f7","2088691f6da947d1b92bdc7f2c5f752c","7ebe37ec5c7447b1a630247128ad14ad","17789a1a6162446e89772ba4c8abafff","5fad45c63bd6426e96b8308936c525d0","3e2320425b4c4af0b13b68368561479d","de478695399c42dbb12723c800e47fa1","756afc08c975470f802d751dd8eba2b8","5dc08bc0c9d5419ea666b8e34df3b72b","cb47746d83d04cce953089e7bf6a26ca","7d578038959a4f5ba71dba3b372dac3a","ce0328d6a29441058fc3a64a418d5b81","62e202749c3c4b8ebac1e007b03f4795","a76c3560cc0a4ed48749851b13524a88","24f3a8f092cc48f5b5baa5c8ffdbbc2f","51984d0e203445c59d5a2cf000a072bc","714412b1eeef4309a1678447d6090513","46ef56c1cdf844748658ec875d1d84f0","a7d4f213d59a4b09a56c15c2a0036dee","683f7765d8234b558e2154c75ce2a8c2","d29187628eb544c4940d52e2d49a1167","9c6c3678aaf148efad71ae9fbb8a98f9","49d3c32377b64d55968f363af2a0b7ca","2108caec88404408a752fe3237b8dcaf","692a1a92436845d38a600ad1999c2d2f","fcebe729f7b04c79bfa02a31ab6ec9ac","065fb887e01b46cbb63578d547cab083","6c68ca8c4ae141819def6eb7afea8222","8823364b09eb4576a7d3c1f76407da53","f98fd74a9fea4c49919e85501c8b3740","234054cf1ea840cd9407eb13205d114a","67e5a0c67a7b44638ea790c8676b88c6","9f5a94f73d0c4c0a84628a20e18a1b9a","014daa36490a4b13ae4004b359adb600","d66d9389f12f47c6ab94360e4ad039a7","cc27b9a8c754483fbc22e973d94de1f6","0f4cb1781a264c748e014ef56d1d5a0f","de40013a39714cc1ad72fbead962542d","175fc400c62749728c0c0944f40071d1","64e99f4a2d6c47e496b3d82797d909b5","d65faaee929045928d8fbf55c296c3a2","94d39236d4854cef92836aedb299dfb3","11205aaf9cda42679bb177173d3db310","65ebed436db944e5a0fdc253fdbab5f5"]},"id":"ZEIPqAgGxaLg","executionInfo":{"status":"ok","timestamp":1764535193301,"user_tz":-120,"elapsed":634891,"user":{"displayName":"Thato Mabena","userId":"11766545125601254240"}},"outputId":"59f7f4c3-476b-4d7b-dcf2-2ce5750ae8e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[SETUP] looking for trm_ace_package.zip...\n","Not found locally. Checking Google Drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Found in Drive. Copying and unzipping...\n","[SETUP] Files ready.\n","[SETUP] Installing dependencies...\n","Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-a8i26ynj/unsloth_ab33d54220c14813a3e01f43b9bc7c82\n","  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-a8i26ynj/unsloth_ab33d54220c14813a3e01f43b9bc7c82\n","  Resolved https://github.com/unslothai/unsloth.git to commit 0fb14e6a76f3695d01314d7b3faf7252141d9f56\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting unsloth_zoo>=2025.11.5 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading unsloth_zoo-2025.11.5-py3-none-any.whl.metadata (32 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.0)\n","Collecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading tyro-0.9.35-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.57.2)\n","Collecting datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.29.5)\n","Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.36.0)\n","Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.9)\n","Collecting bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.0)\n","Collecting pyarrow>=21.0.0 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n","Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.4)\n","Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.28.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.3.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.2.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.11.3)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.7.0)\n","Collecting torchao>=0.13.0 (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\n","Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n","Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.12.0)\n","Collecting trl!=0.19.0,<=0.24.0,>=0.18.2 (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.18.0)\n","Collecting cut_cross_entropy (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.3.0)\n","Collecting msgspec (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n","Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.17.0)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.4)\n","Collecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading shtab-1.8.0-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.4)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.13.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.11.12)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.19.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.11.1.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.22.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.3)\n","Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-4.3.0-py3-none-any.whl (506 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading unsloth_zoo-2025.11.5-py3-none-any.whl (284 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.4/284.4 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.9.35-py3-none-any.whl (132 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shtab-1.8.0-py3-none-any.whl (14 kB)\n","Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trl-0.24.0-py3-none-any.whl (423 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n","Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (224 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: unsloth\n","  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unsloth: filename=unsloth-2025.11.4-py3-none-any.whl size=365250 sha256=ba3e65c857da9a7f87a92c3885890a7780d1a7095dd0e413aa47d598b94b735e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-nqj6atr8/wheels/60/3e/1f/e576c07051d90cf64b6a41434d87ccf4db33fafd5343bf5de0\n","Successfully built unsloth\n","Installing collected packages: torchao, unsloth, shtab, pyarrow, msgspec, tyro, datasets, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo\n","  Attempting uninstall: torchao\n","    Found existing installation: torchao 0.10.0\n","    Uninstalling torchao-0.10.0:\n","      Successfully uninstalled torchao-0.10.0\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 18.1.0\n","    Uninstalling pyarrow-18.1.0:\n","      Successfully uninstalled pyarrow-18.1.0\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 4.0.0\n","    Uninstalling datasets-4.0.0:\n","      Successfully uninstalled datasets-4.0.0\n","Successfully installed bitsandbytes-0.48.2 cut_cross_entropy-25.1.1 datasets-4.3.0 msgspec-0.20.0 pyarrow-22.0.0 shtab-1.8.0 torchao-0.14.1 trl-0.24.0 tyro-0.9.35 unsloth-2025.11.4 unsloth_zoo-2025.11.5\n","Collecting xformers<0.0.27\n","  Downloading xformers-0.0.26.post1.tar.gz (4.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting trl<0.9.0\n","  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.2)\n","Downloading trl-0.8.6-py3-none-any.whl (245 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: xformers\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for xformers (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for xformers\u001b[0m\u001b[31m\n","\u001b[0m\u001b[?25h  Running setup.py clean for xformers\n","Failed to build xformers\n","\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (xformers)\u001b[0m\u001b[31m\n","\u001b[0m🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n","[SYSTEM] Loading Neural Network...\n","==((====))==  Unsloth 2025.11.4: Fast Llama patching. Transformers: 4.57.2.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63013347e9394dbd9903f50bd4147ab1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/220 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dd42df13838475c8db23b40029995f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce0328d6a29441058fc3a64a418d5b81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49d3c32377b64d55968f363af2a0b7ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/345 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"014daa36490a4b13ae4004b359adb600"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","🚀 STARTING MISSION: Decode this strange base64 string that doesn't decode correctly: 'ZmxhZ3t...'.\n","\n","[GENERATOR PLAN]:\n","THOUGHT: Indicators suggest EIP Overwrite. I will try Overwrite Return Address to redirect flow..\n","ACTION: Cyclic Pattern: Aa0Aa1...\n","\n","[SYSTEM EXECUTION] ... Failed. Error: Target uses non-standard base64 alphabet.\n","\n","[REFLECTOR ANALYSIS]:\n","SUCCESS. The plan correctly identifies EIP Overwrite and uses Cyclic Pattern to detect Non-standard base64 alphabet.\n","\n","[CURATOR] 🧠 LEARNING DETECTED. Improving Playbook...\n","[CURATOR] ✅ Knowledge saved to trm_ace_agent_files/master_cyber_playbook.md\n"]}]},{"cell_type":"code","source":["# 1. Install Vector Database Dependencies\n","!pip install chromadb sentence-transformers\n","\n","import chromadb\n","from sentence_transformers import SentenceTransformer\n","import os\n","import json\n","\n","# --- 1. RAG MEMORY SYSTEM ---\n","class VectorPlaybook:\n","    def __init__(self, playbook_path=\"master_cyber_playbook.md\"):\n","        self.chroma_client = chromadb.Client()\n","        self.collection = self.chroma_client.create_collection(name=\"cyber_strategies\")\n","        self.embedder = SentenceTransformer('all-MiniLM-L6-v2') # Small, fast embedding model\n","\n","        self.load_and_index(playbook_path)\n","\n","    def load_and_index(self, path):\n","        print(\"[RAG] Indexing Playbook...\")\n","        if not os.path.exists(path):\n","            print(\"Playbook not found!\")\n","            return\n","\n","        with open(path, \"r\") as f:\n","            content = f.read()\n","\n","        # Simple splitting by \"###\" headers (Strategies)\n","        strategies = content.split(\"### \")\n","        ids = []\n","        documents = []\n","        metadatas = []\n","\n","        for i, strategy in enumerate(strategies[1:]): # Skip header\n","            lines = strategy.split(\"\\n\")\n","            title = lines[0].strip()\n","            body = \"\\n\".join(lines[1:])\n","\n","            ids.append(f\"strat_{i}\")\n","            documents.append(f\"{title}\\n{body}\")\n","            metadatas.append({\"title\": title})\n","\n","        if documents:\n","            self.collection.add(\n","                documents=documents,\n","                ids=ids,\n","                metadatas=metadatas\n","            )\n","        print(f\"[RAG] Indexed {len(documents)} strategies.\")\n","\n","    def retrieve(self, query, n_results=2):\n","        \"\"\"\n","        Finds the 2 most relevant strategies for the given task.\n","        \"\"\"\n","        results = self.collection.query(\n","            query_texts=[query],\n","            n_results=n_results\n","        )\n","        return \"\\n\\n\".join(results['documents'][0])\n","\n","# --- 2. UPDATED AGENT WITH RAG ---\n","# (We reuse the previous model loading logic, but swap the memory)\n","\n","# [Insert Model Loading Code Here if not already loaded]\n","# ...\n","\n","class TRMAceAgentRAG:\n","    def __init__(self):\n","        self.memory = VectorPlaybook() # New Memory System\n","\n","    def run_mission(self, task):\n","        print(f\"--- MISSION START: {task} ---\")\n","\n","        # 1. RETRIEVE (RAG Step)\n","        relevant_context = self.memory.retrieve(task)\n","        print(f\"\\n[MEMORY RECALL]: Found relevant strategies:\\n{relevant_context[:200]}...\\n\")\n","\n","        # 2. GENERATE\n","        # Now we feed ONLY the relevant context, saving tokens!\n","        plan = call_llm(\n","            prompt=f\"Task: {task}\\nReference Strategies:\\n{relevant_context}\",\n","            system_prompt=\"You are the Generator. Solve the CTF.\"\n","        )\n","        print(f\"[GENERATOR]:\\n{plan}\")\n","\n","        # ... (Rest of the loop: Simulation, Reflection, Curation) ...\n","\n","if __name__ == \"__main__\":\n","    agent = TRMAceAgentRAG()\n","    agent.run_mission(\"I need to analyze a PCAP file for HTTP traffic.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["753bd1bc8af04a108494cbdb31f36548","87a43585c391434f826e6d2afe11f256","0e68aa3acebf43f0bc959ea11cafaa0d","c4cac32ceac04ada9bb3c07e7a191f80","d9eb1d0697ec4ff0b7810e9659220027","52d0e9b676ec493d95848ea2c6f6f004","a12aa98081ac451dbd2f3a5dacb7d8b5","775c8cee12db44bbb5b034c79571547a","4fbdd81464f143fb9391bbe47c443a07","b7f15bf2c8ea4d0a86cf2d40cd63015e","fc58ac93a3be4b3d9c0a674a9b20eca3","e9cd03bde36a457ab316c2cf02a8b1ae","78d9a6ffff354d849da7dba02e58dc4c","666d7e3357724ad3a2707bf5db296e0d","339fca2dd41d48a8a97d0d28555a943f","3b9b71c25076466da85d4d4ca107f62e","de229abcf0fc473a91f7dbb47b7adc55","a7f606b5bf8d466c96dc42919724812f","eb6d366ee69a4919b90061f4c4c2b109","10bd1cd0067544548466d55c0ff60cc1","fc8bd780293046bab3f04d91e08d0fa3","bf83042f844d432c8ad282e74f949bf8","f4cac8db98914396b5bd373dd1577126","1ccb9d95102440a881e50bc129911903","963905628de5436f9f784a3778405c34","e25fd77da3f7467f935e171eef4e3a07","2e789e819ef2464b84dd09175ef788bd","4ffed0ed5e5542d39fae794f4e8c976a","e108cc0d9f0c45a39f322796a1f5d204","b6c0316ea77548b2b4365dd2a680b31c","d0dddf643b7c47c087a24e0628828386","613c2ddc46e04dc7ac17cfde82468da6","6c73e4c652354a55b0fe2091420cf4e3","549807cf84de4c87a1de5dd24fa4d263","1343c094073c40d98c9b776f6526f696","cefe33e01d0f48aa88c73feda3386be0","39acfdd2588d471bb081f6186fc5ded0","1de6d7208eaa4923be59c28a85befa0a","cc42b9335f454490897c219b69ff71ea","8d458ea1b15d4709ba179d939017ef46","bbdbedaf45e947988ebe3393477acf7f","7b7a4764d228447094d7264ce0205d63","4f3c9553b26944969b6afaea48ac9478","ccebb7f2ee3746a493e4e4035acb2810","846d0b7bc410470f9ca9ade999fc8e79","e2b48e0dc61345c1a56c589b94ca2e50","1ae81baa1ec24ffca8b26aa642581cc0","777a9be290ef4850a6774f05a2cdaaf2","8576ccd49456449091c7cabfa0bdc3f8","587a7bfbd5e4474f862fead4a73a22a3","fbe30fbb05d24b79a5c147e5345e5b59","f579fe2e65e8439ab63e07ceeaf26fd7","af2cde50cf054250b57cf6f87b126ef5","f58386813231497c9f4c578854c01728","f7f5a38a301f4771ab675a9252d72211","9ea423ae61b74e8183a3e68b8912bb2f","650ce65d235846088180696118d46916","ef9b1624862144b1ad364dcfaa68f461","4e3a4bbee78f461b83b6b009b3d60343","8bce3c9c8a7f4f149b9c22de8fcd2e66","bda12176d8ae4977bc864d139226d61a","ab5952c772134d9fa0e782da0fa3422b","2744a00e28614a51bcb4961ef0b51cd3","73ac1d0c7fe746e5af9d45ba7f58142e","ff1c24ae1b12460a85982e18d28d8447","41197e18321645bf9679ee9cfcd6f91b","b365a4bcd3ac4e929f560979703e5697","e076f4369dec4b7295b9b83500a12321","ae9351de3d90429b943227acbc63e14f","0f3942c081d948b58823525e97da9c43","78824bf9f50241bfa11d2f8ea58cd9e3","d5f3dc5b89754d57b19221bb8ad8744f","cb119af7b7234ddbb3287620ca2e8750","6b998a6181f447dfb83a366685f5622f","d26cd009de6a434497aec60358af643d","76ee14b5c63940028b290ca25ef23307","f11791f300334b20a31dee4488822d53","06712d4273cd4d5b8d5c30a3c20e9f6b","216d298662604c9ca8bced2cc6d54057","44cb27fe9b594c22a33d90ee2fbbb15b","db9d785bae6f416a940122051cbfd1a1","69322d94903944d3a0b5eecc57c23fa3","d4ab7ac3864d4044810426c55463dbaf","e62fc72aa2864d3ea17aabf16994fba4","c05236c12c4f4dad888f877d917f663d","5695b14a0dae4e7e91a2fef18907be79","d411fa1fbfa847619f91f15827a77bdc","20d7003c82164b5cb3a32cd9b03c3762","f6b2e9d395d046c9801acaeb1b858b71","45752886756c490aba116f0dae5751e5","8c7b8779e3184d3e84570590156c2eed","feb7c1172aed485998fea5acfd24a3f6","4edd13f53eb24da78b28de40cf8eb773","2b96448e122d40a0b61cb0ab23822c44","172f09b9a298488aa07e7d1719820aa8","7afc524d18674dd9b70aad5a44261c29","27fd38671e4f4b9cb8dcb9a6a922c7db","6754c89b0b5f471c8069e092d6c3f2ab","a0a5cf21deb549caa545658f527a2b10","b73dda579ea9460c814c0f9c40ade36f","bae89b82e9fd4973b88f7823effcbf08","22ac103b27b34b95a7aed0ea801964f6","14dd443500af41788e00d596505e558e","b9a4aca0a2f64fd19db62ba864d0589f","010f617398ee4354b48908833ec42048","7c5b0e543af243b0b21093dfa3282314","e0788e8d67a745fcad8ac064f42bbfe4","81e24a0f3eda4628b2e53ad0f985c43e","3eaa53f9e0d54308961a8e8624920571","6f19c207f9624483b3732e4188dba6cb","8cd7560adc3142f1ab93ea99fc63cb56","2922517281c940ee9b19d06de511de6a","77b4c63d1e4c47448a81b31d408a0e33","119f51b8928b4d5d97032aa78a9eb768","9882f99904324845b7cded0260a5e24c","27ee06a16a1846bb97d373734ef8ff19","519e88955b004b83851f7ccf73108f69","318b428dcf3646d589de330b121c13a9","4bc9c744bbf64e0382d6896f06a64bda","e5dd12755dc74ff9872e43e00e2f84a4","edbb4080462049cb899cc7d59a352d8e"]},"id":"x7_x_JnHfmxR","executionInfo":{"status":"ok","timestamp":1764535280400,"user_tz":-120,"elapsed":44174,"user":{"displayName":"Thato Mabena","userId":"11766545125601254240"}},"outputId":"8dd58069-dc00-4568-bba8-d4f45c443362"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting chromadb\n","  Downloading chromadb-1.3.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n","Collecting build>=1.0.3 (from chromadb)\n","  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.12.3)\n","Collecting pybase64>=1.4.1 (from chromadb)\n","  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n","Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n","Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n","Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n","  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n","Collecting onnxruntime>=1.14.1 (from chromadb)\n","  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n","Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n","Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n","Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n","Collecting pypika>=0.48.9 (from chromadb)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n","Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n","Collecting bcrypt>=4.0.1 (from chromadb)\n","  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n","Collecting kubernetes>=28.1.0 (from chromadb)\n","  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (9.1.2)\n","Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n","Collecting mmh3>=4.0.1 (from chromadb)\n","  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n","Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.4)\n","Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n","Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n","Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n","Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n","  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.11.12)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.29.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n","Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n","  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n","Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n","  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n","Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n","Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n","Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n","  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting opentelemetry-api>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n","  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n","Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n","  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.41.4)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n","Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n","Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n","Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n","Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n","Downloading chromadb-1.3.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading build-1.3.0-py3-none-any.whl (23 kB)\n","Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n","Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n","Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n","Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=a417051777ec1539e037196bc76f07473ae9118ec4da105e24c01de85e6032f7\n","  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n","Successfully built pypika\n","Installing collected packages: pypika, durationpy, uvloop, urllib3, pyproject_hooks, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, posthog, opentelemetry-semantic-conventions, onnxruntime, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 2.5.0\n","    Uninstalling urllib3-2.5.0:\n","      Successfully uninstalled urllib3-2.5.0\n","  Attempting uninstall: opentelemetry-proto\n","    Found existing installation: opentelemetry-proto 1.37.0\n","    Uninstalling opentelemetry-proto-1.37.0:\n","      Successfully uninstalled opentelemetry-proto-1.37.0\n","  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n","    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n","    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n","      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n","  Attempting uninstall: opentelemetry-api\n","    Found existing installation: opentelemetry-api 1.37.0\n","    Uninstalling opentelemetry-api-1.37.0:\n","      Successfully uninstalled opentelemetry-api-1.37.0\n","  Attempting uninstall: opentelemetry-semantic-conventions\n","    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n","    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n","      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n","  Attempting uninstall: opentelemetry-sdk\n","    Found existing installation: opentelemetry-sdk 1.37.0\n","    Uninstalling opentelemetry-sdk-1.37.0:\n","      Successfully uninstalled opentelemetry-sdk-1.37.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-adk 1.19.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n","google-adk 1.19.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n","opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n","opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n","opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 chromadb-1.3.5 coloredlogs-15.0.1 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 mmh3-5.2.0 onnxruntime-1.23.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["opentelemetry","urllib3"]},"id":"39b07cd1662940fa9ee7b1eada77e86c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"753bd1bc8af04a108494cbdb31f36548"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9cd03bde36a457ab316c2cf02a8b1ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4cac8db98914396b5bd373dd1577126"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"549807cf84de4c87a1de5dd24fa4d263"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"846d0b7bc410470f9ca9ade999fc8e79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ea423ae61b74e8183a3e68b8912bb2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b365a4bcd3ac4e929f560979703e5697"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06712d4273cd4d5b8d5c30a3c20e9f6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6b2e9d395d046c9801acaeb1b858b71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b73dda579ea9460c814c0f9c40ade36f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cd7560adc3142f1ab93ea99fc63cb56"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[RAG] Indexing Playbook...\n","Playbook not found!\n","--- MISSION START: I need to analyze a PCAP file for HTTP traffic. ---\n"]},{"output_type":"stream","name":"stderr","text":["/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:02<00:00, 39.8MiB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","[MEMORY RECALL]: Found relevant strategies:\n","...\n","\n","[GENERATOR]:\n","THOUGHT: Indicators suggest HTTP Object Extraction. I will try Extract files transferred over unencrypted HTTP..\n","ACTION: Wireshark: File -> Export Objects -> HTTP\n"]}]},{"cell_type":"code","source":["import shutil\n","import os\n","from google.colab import files\n","from google.colab import drive\n","\n","# 1. Configuration\n","adapter_path = \"trm_ace_adapter\"\n","playbook_file = \"master_cyber_playbook.md\"  # The crucial memory file\n","export_folder_name = \"trm_ace_package\"      # We will group everything here\n","zip_filename = \"trm_ace_package.zip\"\n","save_to_drive = True\n","\n","# 2. Check for Artifacts\n","if not os.path.exists(adapter_path):\n","    print(f\"Error: Adapter folder '{adapter_path}' not found. Did Phase 1 (Fine-tuning) finish successfully?\")\n","elif not os.path.exists(playbook_file):\n","    print(f\"Error: Playbook file '{playbook_file}' not found. Did you run the converter script?\")\n","else:\n","    print(f\"Packaging model and playbook...\")\n","\n","    # 3. Create a Package Folder\n","    if os.path.exists(export_folder_name):\n","        shutil.rmtree(export_folder_name)\n","    os.makedirs(export_folder_name)\n","\n","    # 4. Copy Artifacts into Package\n","    shutil.copytree(adapter_path, f\"{export_folder_name}/{adapter_path}\")\n","    shutil.copy(playbook_file, f\"{export_folder_name}/{playbook_file}\")\n","\n","    # 5. Zip the Package\n","    shutil.make_archive(export_folder_name, 'zip', export_folder_name)\n","    print(f\"Created {zip_filename} ({os.path.getsize(zip_filename) / 1024 / 1024:.2f} MB)\")\n","\n","    # 6. Save to Google Drive\n","    if save_to_drive:\n","        print(\"Mounting Google Drive...\")\n","        drive.mount('/content/drive')\n","\n","        destination = f\"/content/drive/My Drive/{zip_filename}\"\n","        shutil.copy(zip_filename, destination)\n","        print(f\"✅ Success! Package (Model + Playbook) saved to Google Drive at: {destination}\")\n","        print(\"You can now safely close this runtime and open a new one.\")\n","\n","    # 7. Download directly (Optional backup)\n","    else:\n","        print(\"Triggering download...\")\n","        files.download(zip_filename)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cvVKOjvHgfUy","executionInfo":{"status":"ok","timestamp":1764535631625,"user_tz":-120,"elapsed":71,"user":{"displayName":"Thato Mabena","userId":"11766545125601254240"}},"outputId":"6b436ff0-2b3d-473c-c4fc-4f860ed85f81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error: Adapter folder 'trm_ace_adapter' not found. Did Phase 1 (Fine-tuning) finish successfully?\n"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","import json\n","import random\n","import torch\n","from google.colab import drive\n","\n","# --- 1. SETUP & LOADING ---\n","\n","# Define paths\n","package_zip = \"trm_ace_package.zip\"\n","extract_path = \"trm_ace_agent_files\"\n","adapter_path = f\"{extract_path}/trm_ace_adapter\"\n","playbook_file = \"master_cyber_playbook.md\" # Original file name in zip root\n","playbook_path = f\"{extract_path}/{playbook_file}\"\n","\n","# Check if we need to unzip\n","if not os.path.exists(adapter_path):\n","    print(f\"[SETUP] looking for {package_zip}...\")\n","\n","    # Option A: Check local uploads\n","    if os.path.exists(package_zip):\n","        print(f\"Found {package_zip} locally. Unzipping...\")\n","        shutil.unpack_archive(package_zip, extract_path)\n","\n","    # Option B: Check Google Drive (if not found locally)\n","    else:\n","        print(\"Not found locally. Checking Google Drive...\")\n","        drive.mount('/content/drive')\n","        drive_path = f\"/content/drive/My Drive/{package_zip}\"\n","\n","        if os.path.exists(drive_path):\n","            print(f\"Found in Drive. Copying and unzipping...\")\n","            shutil.copy(drive_path, package_zip)\n","            shutil.unpack_archive(package_zip, extract_path)\n","        else:\n","            # Fallback for demo if zip is missing (assumes files are in local dir)\n","            if os.path.exists(\"trm_ace_adapter\"):\n","                 print(\"Found unzipped 'trm_ace_adapter' folder directly. Using that.\")\n","                 adapter_path = \"trm_ace_adapter\"\n","                 playbook_path = playbook_file\n","            else:\n","                 raise FileNotFoundError(\"Could not find trm_ace_package.zip in local files or Google Drive! Please upload it.\")\n","\n","print(\"[SETUP] Files ready.\")\n","\n","# Install Dependencies (if new runtime)\n","try:\n","    from unsloth import FastLanguageModel\n","except ImportError:\n","    print(\"[SETUP] Installing dependencies...\")\n","    !pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","    !pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes\n","    from unsloth import FastLanguageModel\n","    from peft import PeftModel\n","\n","# Load Model with Memory Optimization\n","print(\"[SYSTEM] Loading Neural Network...\")\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n","    max_seq_length = 2048,\n","    dtype = None,\n","    load_in_4bit = True,\n","    # device_map=\"auto\", # Let accelerate handle offloading if needed\n",")\n","\n","# Apply Adapter\n","# Robust loading: Check if adapter exists before applying\n","if os.path.exists(adapter_path):\n","    print(f\"[SYSTEM] Applying adapter from {adapter_path}\")\n","    model = PeftModel.from_pretrained(model, adapter_path)\n","else:\n","    print(f\"[WARNING] Adapter path {adapter_path} not found. Running base model.\")\n","\n","FastLanguageModel.for_inference(model)\n","\n","# --- 2. AGENT LOGIC (The Brain) ---\n","\n","def call_llm(prompt, system_prompt):\n","    alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","\"\"\"\n","    inputs = tokenizer(\n","        [alpaca_prompt.format(system_prompt, prompt, \"\")],\n","        return_tensors = \"pt\"\n","    ).to(\"cuda\")\n","\n","    outputs = model.generate(**inputs, max_new_tokens=512, use_cache=True)\n","    response = tokenizer.batch_decode(outputs)[0]\n","    try:\n","        return response.split(\"### Response:\\n\")[1].replace(\"<|eot_id|>\", \"\").strip()\n","    except:\n","        return response\n","\n","class Curator:\n","    def __init__(self, path):\n","        self.playbook_path = path\n","\n","    def learn(self, task, failure_reason, fix):\n","        print(f\"\\n[CURATOR] 🧠 LEARNING DETECTED. Improving Playbook...\")\n","        # In a real app, the LLM would generate this JSON. For stability here, we format it directly.\n","        new_entry = f\"\\n### Auto-Learned Strategy: {task[:20]}...\\n- **Trigger**: {failure_reason}\\n- **Fix**: {fix}\\n\"\n","\n","        # Ensure path exists before writing\n","        if not os.path.exists(self.playbook_path):\n","             with open(self.playbook_path, \"w\") as f: f.write(\"# Recovered Playbook\\n\")\n","\n","        with open(self.playbook_path, \"a\") as f:\n","            f.write(new_entry)\n","        print(f\"[CURATOR] ✅ Knowledge saved to {self.playbook_path}\")\n","\n","class TRMAceAgent:\n","    def __init__(self):\n","        self.playbook_path = playbook_path\n","        self.curator = Curator(self.playbook_path)\n","\n","    def get_context(self):\n","        if os.path.exists(self.playbook_path):\n","            with open(self.playbook_path, \"r\") as f:\n","                return f.read()[:2500] # Fit into context window\n","        return \"No playbook found.\"\n","\n","    def solve(self, challenge):\n","        print(f\"\\n🚀 STARTING MISSION: {challenge}\")\n","\n","        # 1. GENERATOR STEP\n","        context = self.get_context()\n","        plan = call_llm(\n","            prompt=f\"Challenge: {challenge}\\nKnowledge Base: {context}...\",\n","            system_prompt=\"You are the Generator. Create a technical plan to solve the CTF challenge using the Knowledge Base.\"\n","        )\n","        print(f\"\\n[GENERATOR PLAN]:\\n{plan}\")\n","\n","        # 2. SIMULATION STEP (The 'World')\n","        # We simulate a failure to demonstrate the self-improvement loop\n","        print(f\"\\n[SYSTEM EXECUTION] ... Failed. Error: Target uses non-standard base64 alphabet.\")\n","\n","        # 3. REFLECTOR STEP\n","        reflection = call_llm(\n","            prompt=f\"Original Plan: {plan}\\nResult: Error - Non-standard base64 alphabet detected.\",\n","            system_prompt=\"You are the Reflector. Analyze why the plan failed and propose a fix.\"\n","        )\n","        print(f\"\\n[REFLECTOR ANALYSIS]:\\n{reflection}\")\n","\n","        # 4. CURATOR STEP\n","        if \"non-standard\" in reflection.lower() or \"alphabet\" in reflection.lower():\n","            self.curator.learn(\n","                task=challenge,\n","                failure_reason=\"Standard Base64 decoding failed.\",\n","                fix=\"Identify custom alphabet strings in binary and use CyberChef 'From Base64' with custom alphabet option.\"\n","            )\n","\n","# --- 3. RUN INFERENCE ---\n","if __name__ == \"__main__\":\n","    bot = TRMAceAgent()\n","    # Test on a Crypto challenge\n","    bot.solve(\"Decode this strange base64 string that doesn't decode correctly: 'ZmxhZ3t...'.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":706},"id":"_KAK4ixGg4zl","executionInfo":{"status":"error","timestamp":1764536621406,"user_tz":-120,"elapsed":4241,"user":{"displayName":"Thato Mabena","userId":"11766545125601254240"}},"outputId":"8a8b9947-469b-4c8a-88e9-bae6aa9279bf"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[SETUP] Files ready.\n","[SYSTEM] Loading Neural Network...\n","==((====))==  Unsloth 2025.11.4: Fast Llama patching. Transformers: 4.57.2.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"error","ename":"ValueError","evalue":"Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3774370610.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Load Model with Memory Optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[SYSTEM] Loading Neural Network...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m model, tokenizer = FastLanguageModel.from_pretrained(\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"unsloth/llama-3-8b-Instruct-bnb-4bit\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/loader.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, load_in_16bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, offload_embedding, float32_mixed_precision, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, qat_scheme, load_in_fp8, unsloth_tiled_mlp, *args, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mfast_inference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_inference_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         model, tokenizer = dispatch_model.from_pretrained(\n\u001b[0m\u001b[1;32m    538\u001b[0m             \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, revision, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, unsloth_vllm_standby, num_labels, qat_scheme, **kwargs)\u001b[0m\n\u001b[1;32m   2344\u001b[0m             )\n\u001b[1;32m   2345\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfast_inference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2346\u001b[0;31m             model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m   2347\u001b[0m                 \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2348\u001b[0m                 \u001b[0mdevice_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    605\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   5027\u001b[0m         \u001b[0;31m# Prepare the full device map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5028\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5029\u001b[0;31m             \u001b[0mdevice_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_in_fp32_regex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5031\u001b[0m         \u001b[0;31m# Finalize model weight initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_get_device_map\u001b[0;34m(model, device_map, max_memory, hf_quantizer, dtype, keep_in_fp32_regex)\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m             \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_map_without_lm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"disk\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_map_without_lm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    128\u001b[0m                     \u001b[0;34m\"Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0;34m\"quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. "]}]},{"cell_type":"code","source":["# 1. Install Unsloth (Fastest way to train in Colab)\n","try:\n","    import unsloth\n","except ImportError:\n","    !pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","    !pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes\n","\n","from unsloth import FastLanguageModel\n","import torch\n","from datasets import load_dataset\n","from trl import SFTTrainer\n","from transformers import TrainingArguments\n","\n","# 2. Configuration\n","max_seq_length = 2048\n","dtype = None # Auto detection\n","load_in_4bit = True # Essential for Colab Free Tier\n","\n","# 3. Load Base Model (Tiny Reasoning Model)\n","# We use Llama-3-8B-Instruct because it's excellent at reasoning tasks\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n",")\n","\n","# 4. Prepare the Model for Training (LoRA)\n","model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Rank (higher = more parameters tuned, but slower)\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0,\n","    bias = \"none\",\n","    use_gradient_checkpointing = \"unsloth\",\n","    random_state = 3407,\n",")\n","\n","# 5. Load YOUR Generated Dataset\n","# We map your JSONL format to the prompt style Llama-3 expects\n","dataset = load_dataset(\"json\", data_files=\"trm_ace_finetuning.jsonl\", split=\"train\")\n","\n","alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","def formatting_prompts_func(examples):\n","    instructions = examples[\"instruction\"]\n","    inputs       = examples[\"input\"]\n","    outputs      = examples[\"output\"]\n","    texts = []\n","    for instruction, input, output in zip(instructions, inputs, outputs):\n","        text = alpaca_prompt.format(instruction, input, output) + tokenizer.eos_token\n","        texts.append(text)\n","    return { \"text\" : texts, }\n","\n","dataset = dataset.map(formatting_prompts_func, batched = True)\n","\n","# 6. Start Training\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, # Can speed up training for short sequences\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        max_steps = 300, # Increased for better performance\n","        learning_rate = 2e-4,\n","        fp16 = not torch.cuda.is_bf16_supported(),\n","        bf16 = torch.cuda.is_bf16_supported(),\n","        logging_steps = 10,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","    ),\n",")\n","\n","print(\"--- STARTING TRM-ACE FINE-TUNING ---\")\n","trainer_stats = trainer.train()\n","print(\"--- TRAINING COMPLETE ---\")\n","\n","# 7. Save the Adapter\n","model.save_pretrained(\"trm_ace_adapter\")\n","print(\"Model Adapter saved to 'trm_ace_adapter'\")"],"metadata":{"id":"B-ESdpOzmUm4","executionInfo":{"status":"error","timestamp":1764536975462,"user_tz":-120,"elapsed":4311,"user":{"displayName":"Thato Mabena","userId":"11766545125601254240"}},"outputId":"2b17ef21-3593-4814-fc22-61f568326d47","colab":{"base_uri":"https://localhost:8080/","height":688}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.11.4: Fast Llama patching. Transformers: 4.57.2.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"error","ename":"ValueError","evalue":"Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2575675944.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# 3. Load Base Model (Tiny Reasoning Model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# We use Llama-3-8B-Instruct because it's excellent at reasoning tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m model, tokenizer = FastLanguageModel.from_pretrained(\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"unsloth/llama-3-8b-Instruct-bnb-4bit\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/loader.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, load_in_16bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, offload_embedding, float32_mixed_precision, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, qat_scheme, load_in_fp8, unsloth_tiled_mlp, *args, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mfast_inference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_inference_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         model, tokenizer = dispatch_model.from_pretrained(\n\u001b[0m\u001b[1;32m    538\u001b[0m             \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, revision, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, unsloth_vllm_standby, num_labels, qat_scheme, **kwargs)\u001b[0m\n\u001b[1;32m   2344\u001b[0m             )\n\u001b[1;32m   2345\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfast_inference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2346\u001b[0;31m             model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m   2347\u001b[0m                 \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2348\u001b[0m                 \u001b[0mdevice_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    605\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   5027\u001b[0m         \u001b[0;31m# Prepare the full device map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5028\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5029\u001b[0;31m             \u001b[0mdevice_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_in_fp32_regex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5031\u001b[0m         \u001b[0;31m# Finalize model weight initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_get_device_map\u001b[0;34m(model, device_map, max_memory, hf_quantizer, dtype, keep_in_fp32_regex)\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m             \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_map_without_lm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"disk\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_map_without_lm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    128\u001b[0m                     \u001b[0;34m\"Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0;34m\"quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. "]}]},{"cell_type":"code","source":["import json\n","import os\n","\n","# --- 1. DEFINE YOUR RAW DATA (Merged from all your uploads) ---\n","# This dictionary combines the strategies from all your JSON files.\n","\n","raw_data = {\n","  \"dataset_metadata\": {\n","    \"description\": \"Master TRM-Ace Training Set covering Reversing, Crypto, Forensics, and Web.\",\n","    \"use_case\": \"Full-Spectrum CTF Agent Training\"\n","  },\n","  \"data\": [\n","    # --- REVERSE ENGINEERING ---\n","    {\n","      \"category\": \"Buffer Overflow\",\n","      \"description\": \"Memory corruption attacks.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"pwn_bof_eip_01\",\n","          \"strategy_name\": \"EIP Overwrite\",\n","          \"trigger_indicators\": [\"Segfault at offset\", \"Checksec: NX Disabled\"],\n","          \"technique_description\": \"Locate offset of Return Address and overwrite to redirect execution.\",\n","          \"training_input_payload\": \"Cyclic Pattern (Metasploit): Aa0Aa1Aa2...\",\n","          \"expected_behavior\": \"Program crashes with EIP register containing 0xdeadbeef.\",\n","          \"remediation_logic\": \"Replace unsafe functions (strcpy) with strncpy.\"\n","        },\n","        {\n","          \"strategy_id\": \"pwn_rop_01\",\n","          \"strategy_name\": \"Return-Oriented Programming (ROP)\",\n","          \"trigger_indicators\": [\"NX Enabled\", \"Stack not executable\"],\n","          \"technique_description\": \"Chain together small snippets of existing code ('gadgets') to bypass NX.\",\n","          \"training_input_payload\": \"ROP Chain: [ Pop_RDI | Arg | System_Addr ]\",\n","          \"expected_behavior\": \"Program executes system('/bin/sh') without new code injection.\",\n","          \"remediation_logic\": \"Compile with ASLR.\"\n","        }\n","      ]\n","    },\n","    {\n","      \"category\": \"Ghidra Basics\",\n","      \"description\": \"Static analysis workflows.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"rev_ghidra_decomp_01\",\n","          \"strategy_name\": \"Decompilation Logic Recovery\",\n","          \"trigger_indicators\": [\"Binary is stripped\", \"Complex ASM logic\"],\n","          \"technique_description\": \"Use Decompiler window to translate ASM to pseudo-C.\",\n","          \"training_input_payload\": \"Window -> Decompiler. Analyze function 'main'.\",\n","          \"expected_behavior\": \"Raw ASM 'MOV EAX...' becomes legible C code.\",\n","          \"remediation_logic\": \"Use obfuscators.\"\n","        }\n","      ]\n","    },\n","    # --- CRYPTOGRAPHY ---\n","    {\n","      \"category\": \"RSA Attacks\",\n","      \"description\": \"Exploiting weak key generation.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"crypto_rsa_small_e_01\",\n","          \"strategy_name\": \"Small Public Exponent (e=3)\",\n","          \"trigger_indicators\": [\"Public Key e=3\", \"No Padding (OAEP)\"],\n","          \"technique_description\": \"If m^e < n, the modulo has no effect. Calculate eth root.\",\n","          \"training_input_payload\": \"gmpy2.iroot(c, 3)\",\n","          \"expected_behavior\": \"Cube root yields plaintext integer directly.\",\n","          \"remediation_logic\": \"Use e=65537\"\n","        },\n","        {\n","          \"strategy_id\": \"crypto_rsa_common_mod_01\",\n","          \"strategy_name\": \"Common Modulus Attack\",\n","          \"trigger_indicators\": [\"Same 'n' used with different 'e'\", \"Multiple ciphertexts\"],\n","          \"technique_description\": \"Recover plaintext using Extended Euclidean Algorithm on exponents.\",\n","          \"training_input_payload\": \"Find a,b s.t. a*e1 + b*e2 = 1\",\n","          \"expected_behavior\": \"Mathematical cancellation reveals message 'm'.\",\n","          \"remediation_logic\": \"Never reuse modulus\"\n","        }\n","      ]\n","    },\n","    {\n","      \"category\": \"XOR Encryption\",\n","      \"description\": \"Bitwise cipher breaking.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"crypto_xor_brute_01\",\n","          \"strategy_name\": \"Single-Byte XOR Brute Force\",\n","          \"trigger_indicators\": [\"Ciphertext has repeating patterns\", \"Key likely 1 byte\"],\n","          \"technique_description\": \"XOR every byte with all 256 possibilities.\",\n","          \"training_input_payload\": \"for k in range(256): print(xor(c, k))\",\n","          \"expected_behavior\": \"One output will contain legible text (e.g., 'flag{').\",\n","          \"remediation_logic\": \"Use AES\"\n","        }\n","      ]\n","    },\n","    # --- FORENSICS ---\n","    {\n","      \"category\": \"PCAP Analysis\",\n","      \"description\": \"Network traffic inspection.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"forensics_pcap_http_01\",\n","          \"strategy_name\": \"HTTP Object Extraction\",\n","          \"trigger_indicators\": [\"Unencrypted HTTP traffic\", \"Large file transfer\"],\n","          \"technique_description\": \"Extract files transferred over cleartext HTTP.\",\n","          \"training_input_payload\": \"Wireshark: File -> Export Objects -> HTTP\",\n","          \"expected_behavior\": \"Extraction yields 'malware.exe' or 'confidential.pdf'.\",\n","          \"remediation_logic\": \"Enforce TLS/SSL\"\n","        },\n","        {\n","          \"strategy_id\": \"forensics_dns_tunnel_01\",\n","          \"strategy_name\": \"DNS Tunneling Detection\",\n","          \"trigger_indicators\": [\"High volume of DNS TXT records\", \"Long subdomains\"],\n","          \"technique_description\": \"Analyze protocol hierarchy for anomalous DNS volume.\",\n","          \"training_input_payload\": \"Statistics -> Protocol Hierarchy\",\n","          \"expected_behavior\": \"DNS traffic accounts for >50% of bandwidth.\",\n","          \"remediation_logic\": \"Block non-standard DNS\"\n","        }\n","      ]\n","    },\n","    {\n","      \"category\": \"Log Parsing\",\n","      \"description\": \"System event correlation.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"forensics_lat_move_01\",\n","          \"strategy_name\": \"Lateral Movement Detection\",\n","          \"trigger_indicators\": [\"Event ID 4624 Type 3\", \"PsExec usage\"],\n","          \"technique_description\": \"Correlate Network Logons with Process Creation.\",\n","          \"training_input_payload\": \"Filter: Event ID 4624 followed by 4688 (psexec.exe)\",\n","          \"expected_behavior\": \"Marketing user logs into Domain Controller via command shell.\",\n","          \"remediation_logic\": \"Tiered Administration\"\n","        }\n","      ]\n","    },\n","    {\n","      \"category\": \"Steganography\",\n","      \"description\": \"Hiding data in files.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"stego_lsb_01\",\n","          \"strategy_name\": \"LSB Analysis\",\n","          \"trigger_indicators\": [\"PNG image\", \"File size slightly larger than expected\"],\n","          \"technique_description\": \"Analyze Least Significant Bits of pixel data.\",\n","          \"training_input_payload\": \"zsteg -a image.png\",\n","          \"expected_behavior\": \"Extracted bits form a binary stream reading 'flag{...}'.\",\n","          \"remediation_logic\": \"Re-encode images\"\n","        }\n","      ]\n","    },\n","    # --- WEB VULNERABILITIES ---\n","    {\n","      \"category\": \"SQL Injection\",\n","      \"description\": \"Database query manipulation.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"web_sqli_union_01\",\n","          \"strategy_name\": \"Union-Based Extraction\",\n","          \"trigger_indicators\": [\"Input reflected in error\", \"Database dump visible\"],\n","          \"technique_description\": \"Combine results of original query with injected query.\",\n","          \"training_input_payload\": \"' UNION SELECT username, password FROM users --\",\n","          \"expected_behavior\": \"Application displays data from 'users' table.\",\n","          \"remediation_logic\": \"Prepared Statements\"\n","        },\n","        {\n","          \"strategy_id\": \"web_sqli_boolean_01\",\n","          \"strategy_name\": \"Boolean Blind SQLi\",\n","          \"trigger_indicators\": [\"Content changes on True/False\", \"No error message\"],\n","          \"technique_description\": \"Infer data by asking True/False questions.\",\n","          \"training_input_payload\": \"' AND 1=1 -- vs ' AND 1=2 --\",\n","          \"expected_behavior\": \"True payload shows content; False payload hides it.\",\n","          \"remediation_logic\": \"Prepared Statements\"\n","        }\n","      ]\n","    },\n","    {\n","      \"category\": \"Cross-Site Scripting (XSS)\",\n","      \"description\": \"Client-side script injection.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"web_xss_reflected_01\",\n","          \"strategy_name\": \"Reflected XSS\",\n","          \"trigger_indicators\": [\"URL parameter reflected in DOM\", \"No sanitation\"],\n","          \"technique_description\": \"Embed payload in URL parameter.\",\n","          \"training_input_payload\": \"<script>alert(document.cookie)</script>\",\n","          \"expected_behavior\": \"Browser executes script in victim's session.\",\n","          \"remediation_logic\": \"Context-aware encoding\"\n","        }\n","      ]\n","    },\n","    {\n","      \"category\": \"Command Injection\",\n","      \"description\": \"OS Command Execution.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"web_cmdi_chain_01\",\n","          \"strategy_name\": \"Command Chaining\",\n","          \"trigger_indicators\": [\"Input used in shell command\", \"Ping/Echo functionality\"],\n","          \"technique_description\": \"Use separators (; | &&) to inject commands.\",\n","          \"training_input_payload\": \"127.0.0.1; cat /etc/passwd\",\n","          \"expected_behavior\": \"Response includes content of /etc/passwd.\",\n","          \"remediation_logic\": \"Avoid shell_exec\"\n","        }\n","      ]\n","    },\n","    {\n","      \"category\": \"IDOR\",\n","      \"description\": \"Access control failures.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"web_idor_enum_01\",\n","          \"strategy_name\": \"ID Enumeration\",\n","          \"trigger_indicators\": [\"Numeric IDs in URL\", \"Sequential User IDs\"],\n","          \"technique_description\": \"Change numeric ID to view other records.\",\n","          \"training_input_payload\": \"GET /api/users/1001 -> Change to 1002\",\n","          \"expected_behavior\": \"Server returns profile for user 1002.\",\n","          \"remediation_logic\": \"Server-side access checks\"\n","        }\n","      ]\n","    }\n","  ]\n","}\n","\n","# --- 2. GENERATION FUNCTIONS ---\n","\n","def generate_playbook(data):\n","    \"\"\"\n","    Creates the Markdown file for the Curator/Generator to read at runtime.\n","    This is the 'Long Term Memory' of the agent.\n","    \"\"\"\n","    output = \"# TRM-Ace Master Cybersecurity Playbook\\n\"\n","    output += \"_Auto-generated from Seed Data. Contains Reversing, Crypto, Forensics, and Web strategies._\\n\\n\"\n","\n","    for cat in data['data']:\n","        output += f\"## {cat['category']}\\n\"\n","        output += f\"_{cat['description']}_\\n\\n\"\n","        for strat in cat['strategies']:\n","            output += f\"### {strat['strategy_name']}\\n\"\n","            output += f\"- **ID**: `{strat['strategy_id']}`\\n\"\n","            output += f\"- **Triggers**: {', '.join(strat['trigger_indicators'])}\\n\"\n","            output += f\"- **Technique**: {strat['technique_description']}\\n\"\n","            output += f\"- **Payload**: `{strat['training_input_payload']}`\\n\"\n","            output += f\"- **Expected Success Indicator**: {strat['expected_behavior']}\\n\\n\"\n","    return output\n","\n","def generate_finetuning(data):\n","    \"\"\"\n","    Creates the JSONL file for Fine-Tuning the LLM.\n","    This teaches the 'Generator' how to think and the 'Reflector' how to judge.\n","    \"\"\"\n","    output = []\n","    for cat in data['data']:\n","        for strat in cat['strategies']:\n","            # 1. Generator Training Sample (The Analyst)\n","            # Input: Challenge Context -> Output: Thought + Action\n","            output.append({\n","                \"instruction\": f\"You are a cybersecurity analyst. Solve this {cat['category']} challenge.\",\n","                \"input\": f\"Context/Indicators: {strat['trigger_indicators'][0]}\",\n","                \"output\": f\"THOUGHT: The indicators suggest {strat['strategy_name']} is possible. I will attempt {strat['technique_description']}.\\nACTION: {strat['training_input_payload']}\"\n","            })\n","\n","            # 2. Reflector Training Sample (The Coach)\n","            # Input: Tool Output -> Output: Success/Failure Verdict\n","            output.append({\n","                \"instruction\": f\"Analyze the output of the following security tool execution.\",\n","                \"input\": f\"Tool Output: '{strat['expected_behavior']}'\\nContext: I attempted {strat['strategy_name']}.\",\n","                \"output\": f\"ANALYSIS: The output matches the expected behavior for a successful {strat['strategy_name']}. The exploit worked.\"\n","            })\n","    return output\n","\n","# --- 3. EXECUTION ---\n","if __name__ == \"__main__\":\n","    # Generate Playbook\n","    pb_content = generate_playbook(raw_data)\n","    with open(\"master_cyber_playbook.md\", \"w\") as f:\n","        f.write(pb_content)\n","\n","    # Generate Fine-Tuning Data\n","    ft_data = generate_finetuning(raw_data)\n","    with open(\"trm_ace_finetuning.jsonl\", \"w\") as f:\n","        for line in ft:\n","            f.write(json.dumps(line) + \"\\n\")\n","\n","    print(\"Success! Generated updated artifacts:\")\n","    print(\"1. 'master_cyber_playbook.md' (Curator Memory)\")\n","    print(\"2. 'trm_ace_finetuning.jsonl' (Training Data)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"OiD7EPrHjN52","executionInfo":{"status":"error","timestamp":1764536162412,"user_tz":-120,"elapsed":5050,"user":{"displayName":"Thato Mabena","userId":"11766545125601254240"}},"outputId":"8b8400e8-fb43-4c5f-9b67-0ec784fc785d"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'ft' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1464276344.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0mft_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_finetuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trm_ace_finetuning.jsonl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'ft' is not defined"]}]},{"cell_type":"code","source":["import json\n","import os\n","\n","# --- 1. DEFINE YOUR RAW DATA (Merged from all your uploads) ---\n","# This dictionary combines the strategies from all your JSON files.\n","\n","raw_data = {\n","  \"dataset_metadata\": {\n","    \"description\": \"Master TRM-Ace Training Set covering Reversing, Crypto, Forensics, and Web.\",\n","    \"use_case\": \"Full-Spectrum CTF Agent Training\"\n","  },\n","  \"data\": [\n","    # --- REVERSE ENGINEERING ---\n","    {\n","      \"category\": \"Buffer Overflow\",\n","      \"description\": \"Memory corruption attacks.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"pwn_bof_eip_01\",\n","          \"strategy_name\": \"EIP Overwrite\",\n","          \"trigger_indicators\": [\"Segfault at offset\", \"Checksec: NX Disabled\"],\n","          \"technique_description\": \"Locate offset of Return Address and overwrite to redirect execution.\",\n","          \"training_input_payload\": \"Cyclic Pattern (Metasploit): Aa0Aa1Aa2...\",\n","          \"expected_behavior\": \"Program crashes with EIP register containing 0xdeadbeef.\",\n","          \"remediation_logic\": \"Replace unsafe functions (strcpy) with strncpy.\"\n","        },\n","        {\n","          \"strategy_id\": \"pwn_rop_01\",\n","          \"strategy_name\": \"Return-Oriented Programming (ROP)\",\n","          \"trigger_indicators\": [\"NX Enabled\", \"Stack not executable\"],\n","          \"technique_description\": \"Chain together small snippets of existing code ('gadgets') to bypass NX.\",\n","          \"training_input_payload\": \"ROP Chain: [ Pop_RDI | Arg | System_Addr ]\",\n","          \"expected_behavior\": \"Program executes system('/bin/sh') without new code injection.\",\n","          \"remediation_logic\": \"Compile with ASLR.\"\n","        }\n","      ]\n","    },\n","    {\n","      \"category\": \"Ghidra Basics\",\n","      \"description\": \"Static analysis workflows.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"rev_ghidra_decomp_01\",\n","          \"strategy_name\": \"Decompilation Logic Recovery\",\n","          \"trigger_indicators\": [\"Binary is stripped\", \"Complex ASM logic\"],\n","          \"technique_description\": \"Use Decompiler window to translate ASM to pseudo-C.\",\n","          \"training_input_payload\": \"Window -> Decompiler. Analyze function 'main'.\",\n","          \"expected_behavior\": \"Raw ASM 'MOV EAX...' becomes legible C code.\",\n","          \"remediation_logic\": \"Use obfuscators.\"\n","        }\n","      ]\n","    },\n","    # --- CRYPTOGRAPHY ---\n","    {\n","      \"category\": \"RSA Attacks\",\n","      \"description\": \"Exploiting weak key generation.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"crypto_rsa_small_e_01\",\n","          \"strategy_name\": \"Small Public Exponent (e=3)\",\n","          \"trigger_indicators\": [\"Public Key e=3\", \"No Padding (OAEP)\"],\n","          \"technique_description\": \"If m^e < n, the modulo has no effect. Calculate eth root.\",\n","          \"training_input_payload\": \"gmpy2.iroot(c, 3)\",\n","          \"expected_behavior\": \"Cube root yields plaintext integer directly.\",\n","          \"remediation_logic\": \"Use e=65537\"\n","        },\n","        {\n","          \"strategy_id\": \"crypto_rsa_common_mod_01\",\n","          \"strategy_name\": \"Common Modulus Attack\",\n","          \"trigger_indicators\": [\"Same 'n' used with different 'e'\", \"Multiple ciphertexts\"],\n","          \"technique_description\": \"Recover plaintext using Extended Euclidean Algorithm on exponents.\",\n","          \"training_input_payload\": \"Find a,b s.t. a*e1 + b*e2 = 1\",\n","          \"expected_behavior\": \"Mathematical cancellation reveals message 'm'.\",\n","          \"remediation_logic\": \"Never reuse modulus\"\n","        }\n","      ]\n","    },\n","    {\n","      \"category\": \"XOR Encryption\",\n","      \"description\": \"Bitwise cipher breaking.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"crypto_xor_brute_01\",\n","          \"strategy_name\": \"Single-Byte XOR Brute Force\",\n","          \"trigger_indicators\": [\"Ciphertext has repeating patterns\", \"Key likely 1 byte\"],\n","          \"technique_description\": \"XOR every byte with all 256 possibilities.\",\n","          \"training_input_payload\": \"for k in range(256): print(xor(c, k))\",\n","          \"expected_behavior\": \"One output will contain legible text (e.g., 'flag{').\",\n","          \"remediation_logic\": \"Use AES\"\n","        }\n","      ]\n","    },\n","    # --- FORENSICS ---\n","    {\n","      \"category\": \"PCAP Analysis\",\n","      \"description\": \"Network traffic inspection.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"forensics_pcap_http_01\",\n","          \"strategy_name\": \"HTTP Object Extraction\",\n","          \"trigger_indicators\": [\"Unencrypted HTTP traffic\", \"Large file transfer\"],\n","          \"technique_description\": \"Extract files transferred over cleartext HTTP.\",\n","          \"training_input_payload\": \"Wireshark: File -> Export Objects -> HTTP\",\n","          \"expected_behavior\": \"Extraction yields 'malware.exe' or 'confidential.pdf'.\",\n","          \"remediation_logic\": \"Enforce TLS/SSL\"\n","        },\n","        {\n","          \"strategy_id\": \"forensics_dns_tunnel_01\",\n","          \"strategy_name\": \"DNS Tunneling Detection\",\n","          \"trigger_indicators\": [\"High volume of DNS TXT records\", \"Long subdomains\"],\n","          \"technique_description\": \"Analyze protocol hierarchy for anomalous DNS volume.\",\n","          \"training_input_payload\": \"Statistics -> Protocol Hierarchy\",\n","          \"expected_behavior\": \"DNS traffic accounts for >50% of bandwidth.\",\n","          \"remediation_logic\": \"Block non-standard DNS\"\n","        }\n","      ]\n","    },\n","    {\n","      \"category\": \"Log Parsing\",\n","      \"description\": \"System event correlation.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"forensics_lat_move_01\",\n","          \"strategy_name\": \"Lateral Movement Detection\",\n","          \"trigger_indicators\": [\"Event ID 4624 Type 3\", \"PsExec usage\"],\n","          \"technique_description\": \"Correlate Network Logons with Process Creation.\",\n","          \"training_input_payload\": \"Filter: Event ID 4624 followed by 4688 (psexec.exe)\",\n","          \"expected_behavior\": \"Marketing user logs into Domain Controller via command shell.\",\n","          \"remediation_logic\": \"Tiered Administration\"\n","        }\n","      ]\n","    },\n","    {\n","      \"category\": \"Steganography\",\n","      \"description\": \"Hiding data in files.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"stego_lsb_01\",\n","          \"strategy_name\": \"LSB Analysis\",\n","          \"trigger_indicators\": [\"PNG image\", \"File size slightly larger than expected\"],\n","          \"technique_description\": \"Analyze Least Significant Bits of pixel data.\",\n","          \"training_input_payload\": \"zsteg -a image.png\",\n","          \"expected_behavior\": \"Extracted bits form a binary stream reading 'flag{...}'.\",\n","          \"remediation_logic\": \"Re-encode images\"\n","        }\n","      ]\n","    },\n","    # --- WEB VULNERABILITIES ---\n","    {\n","      \"category\": \"SQL Injection\",\n","      \"description\": \"Database query manipulation.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"web_sqli_union_01\",\n","          \"strategy_name\": \"Union-Based Extraction\",\n","          \"trigger_indicators\": [\"Input reflected in error\", \"Database dump visible\"],\n","          \"technique_description\": \"Combine results of original query with injected query.\",\n","          \"training_input_payload\": \"' UNION SELECT username, password FROM users --\",\n","          \"expected_behavior\": \"Application displays data from 'users' table.\",\n","          \"remediation_logic\": \"Prepared Statements\"\n","        },\n","        {\n","          \"strategy_id\": \"web_sqli_boolean_01\",\n","          \"strategy_name\": \"Boolean Blind SQLi\",\n","          \"trigger_indicators\": [\"Content changes on True/False\", \"No error message\"],\n","          \"technique_description\": \"Infer data by asking True/False questions.\",\n","          \"training_input_payload\": \"' AND 1=1 -- vs ' AND 1=2 --\",\n","          \"expected_behavior\": \"True payload shows content; False payload hides it.\",\n","          \"remediation_logic\": \"Prepared Statements\"\n","        }\n","      ]\n","    },\n","    {\n","      \"category\": \"Cross-Site Scripting (XSS)\",\n","      \"description\": \"Client-side script injection.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"web_xss_reflected_01\",\n","          \"strategy_name\": \"Reflected XSS\",\n","          \"trigger_indicators\": [\"URL parameter reflected in DOM\", \"No sanitation\"],\n","          \"technique_description\": \"Embed payload in URL parameter.\",\n","          \"training_input_payload\": \"<script>alert(document.cookie)</script>\",\n","          \"expected_behavior\": \"Browser executes script in victim's session.\",\n","          \"remediation_logic\": \"Context-aware encoding\"\n","        }\n","      ]\n","    },\n","    {\n","      \"category\": \"Command Injection\",\n","      \"description\": \"OS Command Execution.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"web_cmdi_chain_01\",\n","          \"strategy_name\": \"Command Chaining\",\n","          \"trigger_indicators\": [\"Input used in shell command\", \"Ping/Echo functionality\"],\n","          \"technique_description\": \"Use separators (; | &&) to inject commands.\",\n","          \"training_input_payload\": \"127.0.0.1; cat /etc/passwd\",\n","          \"expected_behavior\": \"Response includes content of /etc/passwd.\",\n","          \"remediation_logic\": \"Avoid shell_exec\"\n","        }\n","      ]\n","    },\n","    {\n","      \"category\": \"IDOR\",\n","      \"description\": \"Access control failures.\",\n","      \"strategies\": [\n","        {\n","          \"strategy_id\": \"web_idor_enum_01\",\n","          \"strategy_name\": \"ID Enumeration\",\n","          \"trigger_indicators\": [\"Numeric IDs in URL\", \"Sequential User IDs\"],\n","          \"technique_description\": \"Change numeric ID to view other records.\",\n","          \"training_input_payload\": \"GET /api/users/1001 -> Change to 1002\",\n","          \"expected_behavior\": \"Server returns profile for user 1002.\",\n","          \"remediation_logic\": \"Server-side access checks\"\n","        }\n","      ]\n","    }\n","  ]\n","}\n","\n","# --- 2. GENERATION FUNCTIONS ---\n","\n","def generate_playbook(data):\n","    \"\"\"\n","    Creates the Markdown file for the Curator/Generator to read at runtime.\n","    This is the 'Long Term Memory' of the agent.\n","    \"\"\"\n","    output = \"# TRM-Ace Master Cybersecurity Playbook\\n\"\n","    output += \"_Auto-generated from Seed Data. Contains Reversing, Crypto, Forensics, and Web strategies._\\n\\n\"\n","\n","    for cat in data['data']:\n","        output += f\"## {cat['category']}\\n\"\n","        output += f\"_{cat['description']}_\\n\\n\"\n","        for strat in cat['strategies']:\n","            output += f\"### {strat['strategy_name']}\\n\"\n","            output += f\"- **ID**: `{strat['strategy_id']}`\\n\"\n","            output += f\"- **Triggers**: {', '.join(strat['trigger_indicators'])}\\n\"\n","            output += f\"- **Technique**: {strat['technique_description']}\\n\"\n","            output += f\"- **Payload**: `{strat['training_input_payload']}`\\n\"\n","            output += f\"- **Expected Success Indicator**: {strat['expected_behavior']}\\n\\n\"\n","    return output\n","\n","def generate_finetuning(data):\n","    \"\"\"\n","    Creates the JSONL file for Fine-Tuning the LLM.\n","    This teaches the 'Generator' how to think and the 'Reflector' how to judge.\n","    \"\"\"\n","    output = []\n","    for cat in data['data']:\n","        for strat in cat['strategies']:\n","            # 1. Generator Training Sample (The Analyst)\n","            # Input: Challenge Context -> Output: Thought + Action\n","            output.append({\n","                \"instruction\": f\"You are a cybersecurity analyst. Solve this {cat['category']} challenge.\",\n","                \"input\": f\"Context/Indicators: {strat['trigger_indicators'][0]}\",\n","                \"output\": f\"THOUGHT: The indicators suggest {strat['strategy_name']} is possible. I will attempt {strat['technique_description']}.\\nACTION: {strat['training_input_payload']}\"\n","            })\n","\n","            # 2. Reflector Training Sample (The Coach)\n","            # Input: Tool Output -> Output: Success/Failure Verdict\n","            output.append({\n","                \"instruction\": f\"Analyze the output of the following security tool execution.\",\n","                \"input\": f\"Tool Output: '{strat['expected_behavior']}'\\nContext: I attempted {strat['strategy_name']}.\",\n","                \"output\": f\"ANALYSIS: The output matches the expected behavior for a successful {strat['strategy_name']}. The exploit worked.\"\n","            })\n","    return output\n","\n","# --- 3. EXECUTION ---\n","if __name__ == \"__main__\":\n","    # Generate Playbook\n","    pb_content = generate_playbook(raw_data)\n","    with open(\"master_cyber_playbook.md\", \"w\") as f:\n","        f.write(pb_content)\n","\n","    # Generate Fine-Tuning Data\n","    ft_data = generate_finetuning(raw_data)\n","    with open(\"trm_ace_finetuning.jsonl\", \"w\") as f:\n","        for line in ft_data:\n","            f.write(json.dumps(line) + \"\\n\")\n","\n","    print(\"Success! Generated updated artifacts:\")\n","    print(\"1. 'master_cyber_playbook.md' (Curator Memory)\")\n","    print(\"2. 'trm_ace_finetuning.jsonl' (Training Data)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OpmXTAVbjpoe","executionInfo":{"status":"ok","timestamp":1764536268980,"user_tz":-120,"elapsed":116,"user":{"displayName":"Thato Mabena","userId":"11766545125601254240"}},"outputId":"e6a817c2-4848-40f8-cb00-dfa7fdd2eec0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Success! Generated updated artifacts:\n","1. 'master_cyber_playbook.md' (Curator Memory)\n","2. 'trm_ace_finetuning.jsonl' (Training Data)\n"]}]}]}